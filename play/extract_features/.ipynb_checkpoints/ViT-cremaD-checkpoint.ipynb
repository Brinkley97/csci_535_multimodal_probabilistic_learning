{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73285297-aaac-4a84-9674-1e34fd5954c6",
   "metadata": {},
   "source": [
    "# Extracting Features with ViT\n",
    "- https://huggingface.co/docs/transformers/model_doc/vit#vision-transformer-vit\n",
    "- https://arxiv.org/abs/2010.11929"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dec1477-5216-45f8-8bd2-a178186168bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 08:52:47.854232: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from transformers import ViTImageProcessor, ViTFeatureExtractor, ViTModel\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dba20bd1-54fe-4b63-af56-df2ee86d7a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = '/Users/brinkley97/Documents/development/'\n",
    "CLASS_PATH = 'classes/csci_535_multimodal_probabilistic_learning/'\n",
    "DATASET_PATH = 'datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4fdf4ea-1350-468c-b1a4-1bcb9379d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61987b25-6171-43d0-b448-b097b3447425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    original_data = pd.read_csv(file)\n",
    "    # original_data = pd.DataFrame(file)\n",
    "    copy_of_data = original_data.copy()\n",
    "    return copy_of_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a58cb5d2-21d4-4523-a66a-27255a7b5234",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = BASE + CLASS_PATH + DATASET_PATH + 'cremaD_mspR_mspT.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98a6401e-3beb-497b-8666-8f209a9c9130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CREMA-D Paths</th>\n",
       "      <th>MSP R Paths</th>\n",
       "      <th>MSP T Paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114818</th>\n",
       "      <td>114818</td>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114819</th>\n",
       "      <td>114819</td>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114820</th>\n",
       "      <td>114820</td>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114821</th>\n",
       "      <td>114821</td>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114822</th>\n",
       "      <td>114822</td>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114823 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                      CREMA-D Paths  \\\n",
       "0                0  /Users/brinkley97/Documents/development/classe...   \n",
       "1                1  /Users/brinkley97/Documents/development/classe...   \n",
       "2                2  /Users/brinkley97/Documents/development/classe...   \n",
       "3                3  /Users/brinkley97/Documents/development/classe...   \n",
       "4                4  /Users/brinkley97/Documents/development/classe...   \n",
       "...            ...                                                ...   \n",
       "114818      114818  /Users/brinkley97/Documents/development/classe...   \n",
       "114819      114819  /Users/brinkley97/Documents/development/classe...   \n",
       "114820      114820  /Users/brinkley97/Documents/development/classe...   \n",
       "114821      114821  /Users/brinkley97/Documents/development/classe...   \n",
       "114822      114822  /Users/brinkley97/Documents/development/classe...   \n",
       "\n",
       "                                              MSP R Paths  \\\n",
       "0       /Users/brinkley97/Documents/development/classe...   \n",
       "1       /Users/brinkley97/Documents/development/classe...   \n",
       "2       /Users/brinkley97/Documents/development/classe...   \n",
       "3       /Users/brinkley97/Documents/development/classe...   \n",
       "4       /Users/brinkley97/Documents/development/classe...   \n",
       "...                                                   ...   \n",
       "114818                                                NaN   \n",
       "114819                                                NaN   \n",
       "114820                                                NaN   \n",
       "114821                                                NaN   \n",
       "114822                                                NaN   \n",
       "\n",
       "                                              MSP T Paths  \n",
       "0       /Users/brinkley97/Documents/development/classe...  \n",
       "1       /Users/brinkley97/Documents/development/classe...  \n",
       "2       /Users/brinkley97/Documents/development/classe...  \n",
       "3       /Users/brinkley97/Documents/development/classe...  \n",
       "4       /Users/brinkley97/Documents/development/classe...  \n",
       "...                                                   ...  \n",
       "114818                                                NaN  \n",
       "114819                                                NaN  \n",
       "114820                                                NaN  \n",
       "114821                                                NaN  \n",
       "114822                                                NaN  \n",
       "\n",
       "[114823 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_paths_copy = load_data(file_paths)\n",
    "dataset_paths_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220f9b18-5f69-4863-a454-274d2015bcb4",
   "metadata": {},
   "source": [
    "# CREMA-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ae56a4d-2706-4bcb-92df-1fd58d10b8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         /Users/brinkley97/Documents/development/classe...\n",
       "1         /Users/brinkley97/Documents/development/classe...\n",
       "2         /Users/brinkley97/Documents/development/classe...\n",
       "3         /Users/brinkley97/Documents/development/classe...\n",
       "4         /Users/brinkley97/Documents/development/classe...\n",
       "                                ...                        \n",
       "114818    /Users/brinkley97/Documents/development/classe...\n",
       "114819    /Users/brinkley97/Documents/development/classe...\n",
       "114820    /Users/brinkley97/Documents/development/classe...\n",
       "114821    /Users/brinkley97/Documents/development/classe...\n",
       "114822    /Users/brinkley97/Documents/development/classe...\n",
       "Name: CREMA-D Paths, Length: 114823, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crema_d_paths = dataset_paths_copy[\"CREMA-D Paths\"]\n",
    "crema_d_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25a0d157-4348-4c3a-acdd-09f838478432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300    /Users/brinkley97/Documents/development/classe...\n",
       "301    /Users/brinkley97/Documents/development/classe...\n",
       "302    /Users/brinkley97/Documents/development/classe...\n",
       "303    /Users/brinkley97/Documents/development/classe...\n",
       "304    /Users/brinkley97/Documents/development/classe...\n",
       "                             ...                        \n",
       "596    /Users/brinkley97/Documents/development/classe...\n",
       "597    /Users/brinkley97/Documents/development/classe...\n",
       "598    /Users/brinkley97/Documents/development/classe...\n",
       "599    /Users/brinkley97/Documents/development/classe...\n",
       "600    /Users/brinkley97/Documents/development/classe...\n",
       "Name: CREMA-D Paths, Length: 301, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_set_crema_d_paths = crema_d_paths.loc[300:600]\n",
    "sub_set_crema_d_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0cc6916-5f13-4575-9f28-621f7f6501d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/emotion_rec_from_audiovisual/lib/python3.9/site-packages/pandas/core/indexes/range.py:391\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_range\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mValueError\u001b[0m: 0 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m crema_d_path_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sub_set_crema_d_paths)):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# print(crema_d_path_idx)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     crema_d_path \u001b[38;5;241m=\u001b[39m \u001b[43msub_set_crema_d_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcrema_d_path_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m     specific_frame \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(crema_d_path)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# print(np.shape(specific_frame))\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/emotion_rec_from_audiovisual/lib/python3.9/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/emotion_rec_from_audiovisual/lib/python3.9/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/emotion_rec_from_audiovisual/lib/python3.9/site-packages/pandas/core/indexes/range.py:393\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_range\u001b[38;5;241m.\u001b[39mindex(new_key)\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 393\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "    \n",
    "for crema_d_path_idx in range(len(sub_set_crema_d_paths)):\n",
    "    # print(crema_d_path_idx)\n",
    "    crema_d_path = sub_set_crema_d_paths[crema_d_path_idx]\n",
    "    \n",
    "    specific_frame = Image.open(crema_d_path)\n",
    "    # print(np.shape(specific_frame))\n",
    "\n",
    "    inputs = processor(images=specific_frame, return_tensors=\"pt\")\n",
    "    x.append(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9126bd45-1f78-4788-b51e-52907fbea129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa26c3a6-04f5-4fb2-8186-50f16b522cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd1affc-7799-4314-8f29-9810fc6ccdce",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aa4bcf-6732-4bd9-93bc-059c6f21bf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_set_crema_d = BASE + CLASS_PATH + DATASET_PATH + 'subsets_vit/' + 'inputs-cremaD_subset2.txt'\n",
    "sub_set_crema_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41cb6c2-c390-4074-8f3a-a7389723d703",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sub_set_crema_d, 'wb') as f:\n",
    "    pickle.dump(x, f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49955c34-ff47-49e7-ad48-d257756e5df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reading_sub_set_crema_d = pd.read_pickle(sub_set_crema_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd0903-58f2-4304-a705-769edd3282f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading_sub_set_crema_d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae554c9f-a606-4c46-a138-a5c0c80621bd",
   "metadata": {},
   "source": [
    "# Hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2bcea0-0003-4fe2-b212-9138d500b12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_last_hidden_states = []\n",
    "\n",
    "for specific_frame in range(len(reading_sub_set_crema_d)):\n",
    "    inputs = reading_sub_set_crema_d[specific_frame]\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "    # last_hidden_states == representation (1 and 2 with GradCam)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    all_last_hidden_states.append(last_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b61f4a9-c547-4569-ad74-6d3dece8e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3cbd434-4a7b-4f39-afe5-d8ea58a8f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "crema_d_hidden_states = BASE + CLASS_PATH + DATASET_PATH + 'subsets_vit/' + 'hiddenStates-cremaD_subset2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd9b782-ab32-440e-acc3-69b84abe8b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(crema_d_hidden_states, 'wb') as f:\n",
    "    pickle.dump(all_last_hidden_states, f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a6509d1-bce5-483d-8b73-b05b4bfddb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "reading_crema_d_hidden_states = pd.read_pickle(crema_d_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7da8d427-4b1e-44ba-87d9-90c5cc01ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading_crema_d_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49ee0684-c2e2-4d54-82e7-ff7b59c2a3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_per_video = torch.empty((0, 197, 768))\n",
    "save_efs = []\n",
    "\n",
    "for specific_frame_hs in range(len(reading_crema_d_hidden_states)):\n",
    "    \n",
    "    hs = reading_crema_d_hidden_states[specific_frame_hs]\n",
    "    extracted_features_per_video = torch.vstack((extracted_features_per_video, hs))\n",
    "    \n",
    "    save_efs.append(extracted_features_per_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36bbce9-68bf-49b7-a3e5-7338026c3230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_efs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8f4841c-070b-4b81-81b5-f6eb1c7c6229",
   "metadata": {},
   "outputs": [],
   "source": [
    "crema_d_extracted_features = BASE + CLASS_PATH + DATASET_PATH + 'subsets_vit/' + 'extractedFeatures-CremaD_subset2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9f5870f-c5b7-49c2-84fe-4c044d62c303",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(save_efs, crema_d_extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f7bc1e6-d469-4973-ae2e-cd2e161b9161",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_crema_d = torch.load(crema_d_extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1eefe439-aeac-4794-8da5-edfc5d7058c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe_crema_d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
