{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59281649-f273-4153-933e-b3f76eed43a8",
   "metadata": {},
   "source": [
    "# Crop Face with autocrop\n",
    "https://leblancfg.com/autocrop/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4ed7d8d-c0de-4713-8c2b-976117e26773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sys import exit\n",
    "from PIL import Image\n",
    "from autocrop import Cropper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da01634a-8a7b-44de-8b99-0ecbbf47c4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = '/Users/brinkley97/Documents/development/'\n",
    "CLASS_PATH = 'classes/csci_535_multimodal_probabilistic_learning/'\n",
    "DATASET_PATH = 'datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9842d90-2512-4185-8239-fc97c2bd74eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropper = Cropper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e69ce1f-e364-4844-94f4-187396af5818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_frame(path_to_video_frames, video_with_frames, save_location):\n",
    "    \"\"\"Crop the face of video frames and save\n",
    "    \n",
    "    Parameters:\n",
    "    path_to_video_frames -- py str (of path to each list of frames per video)\n",
    "    video with frames -- py list (of frame file name per video)\n",
    "    save_location -- py str (of where to save the cropped face)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # print(video_with_frames)\n",
    "    # count_missing_frames = 0\n",
    "    \n",
    "    for video_with_frame in range(len(video_with_frames)):\n",
    "        specific_frame = video_with_frames[video_with_frame]\n",
    "        \n",
    "        frame_path_with_frames = path_to_video_frames + specific_frame\n",
    "        # print(frame_path_with_frames)\n",
    "        \n",
    "        frame = cropper.crop(frame_path_with_frames)\n",
    "        \n",
    "        if frame is None:\n",
    "            # print(specific_frame, frame)\n",
    "            # count_missing_frames += 1\n",
    "            continue\n",
    "        frame_to_face_cropper = Image.fromarray(frame)\n",
    "        \n",
    "        path_to_save_cropped_face = save_location + specific_frame\n",
    "        \n",
    "\n",
    "        frame_to_face_cropper.save(path_to_save_cropped_face)\n",
    "        # print(\"saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e46e520f-4437-478c-832d-d3b8f3f05672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_path(path_to_frames, SAVE_CROPPED_FRAMES_PATH):\n",
    "    \"\"\"Take the video frames and pass to function to crop the face\n",
    "    \n",
    "    Parameters:\n",
    "    path_to_frames -- str (of a single path to all video frames)\n",
    "    SAVE_CROPPED_FRAMES_PATH -- str (of a single path to save all cropped faces)\n",
    "    \n",
    "    Function calls: \n",
    "    crop_frame\n",
    "    \n",
    "    \"\"\"\n",
    "    store_features_from_frames = []\n",
    "    list_folders_with_frames_name = []\n",
    "    \n",
    "    count_number_files_in_dir = 0\n",
    "    frame_folder_files = os.listdir(path_to_frames)\n",
    "    # print(frame_folder_files)\n",
    "  \n",
    "    for frame_folder_file_idx in range(len(frame_folder_files)):\n",
    "        folders_with_frames_name = frame_folder_files[frame_folder_file_idx]\n",
    "        path_to_video_frames = path_to_frames + folders_with_frames_name + \"/\"\n",
    "        # print(path_to_video_frames)\n",
    "        folder_exists = os.path.isdir(path_to_video_frames)\n",
    "        # print(folder_exists, path_to_video_frames)\n",
    "\n",
    "        if folder_exists == True:          \n",
    "#             \n",
    "            list_frames_per_video = os.listdir(path_to_video_frames)\n",
    "            name_of_frame_folder = frame_folder_files[frame_folder_file_idx]\n",
    "            print(name_of_frame_folder)\n",
    "            save_location = SAVE_CROPPED_FRAMES_PATH + name_of_frame_folder + \"_to_cropped_face/\"\n",
    "            save_location_folder_exists = os.path.exists(save_location)\n",
    "            path_empty = os.listdir(save_location)\n",
    "    \n",
    "            print(path_empty, save_location)\n",
    "            # save_location.replace(\" \", \"\")\n",
    "            # os.mkdir(save_location)\n",
    "\n",
    "#             croppings = crop_frame(path_to_video_frames, list_frames_per_video, save_location)\n",
    "            print()\n",
    "#         else:\n",
    "#             pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c87111b-1e54-4c2f-a55c-adfb6d9a15da",
   "metadata": {},
   "source": [
    "# CREMA-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88f152ad-3162-401c-badd-a404227e12c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREMA_D_PATH = 'git_lfs/CREMA-D/sample_VideoFlash2/all_frames/'\n",
    "SAVE_CREMA_D_PATH = 'git_lfs/CREMA-D/sample_VideoFlash2/all_faces/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5fdf1fda-b280-4768-9a7c-a67b32d429c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREMA_D_FRAMES_PATH = BASE + CLASS_PATH + DATASET_PATH + CREMA_D_PATH\n",
    "# CREMA_D_FRAMES_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06faa666-68b9-4254-a9e0-089b6bd88006",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_CREMA_D_CROPPED_FRAMES_PATH = BASE + CLASS_PATH + DATASET_PATH + SAVE_CREMA_D_PATH\n",
    "# SAVE_CREMA_D_CROPPED_FRAMES_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eccd52cd-0cb8-42e9-afc8-1686c602d5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001_DFA_FEA_XX_frames\n",
      "['frame46.jpg', 'frame52.jpg', 'frame53.jpg', 'frame47.jpg', 'frame51.jpg', 'frame45.jpg', 'frame44.jpg', 'frame50.jpg', 'frame54.jpg', 'frame40.jpg', 'frame41.jpg', 'frame55.jpg', 'frame43.jpg', 'frame57.jpg', 'frame56.jpg', 'frame42.jpg', 'frame19.jpg', 'frame25.jpg', 'frame31.jpg', 'frame30.jpg', 'frame24.jpg', 'frame18.jpg', 'frame32.jpg', 'frame26.jpg', 'frame27.jpg', 'frame33.jpg', 'frame37.jpg', 'frame23.jpg', 'frame22.jpg', 'frame36.jpg', 'frame20.jpg', 'frame34.jpg', 'frame9.jpg', 'frame8.jpg', 'frame35.jpg', 'frame21.jpg', 'frame38.jpg', 'frame5.jpg', 'frame10.jpg', 'frame11.jpg', 'frame4.jpg', 'frame39.jpg', 'frame6.jpg', 'frame13.jpg', 'frame12.jpg', 'frame7.jpg', 'frame3.jpg', 'frame16.jpg', 'frame17.jpg', 'frame2.jpg', 'frame0.jpg', 'frame15.jpg', 'frame29.jpg', 'frame28.jpg', 'frame14.jpg', 'frame1.jpg', 'frame58.jpg', 'frame64.jpg', 'frame59.jpg', 'frame61.jpg', 'frame49.jpg', 'frame48.jpg', 'frame60.jpg', 'frame62.jpg', 'frame63.jpg'] /Users/brinkley97/Documents/development/classes/csci_535_multimodal_probabilistic_learning/datasets/git_lfs/CREMA-D/sample_VideoFlash2/all_faces/1001_DFA_FEA_XX_frames_to_cropped_face/\n",
      "\n",
      "1001_DFA_ANG_XX_frames\n",
      "['frame46.jpg', 'frame52.jpg', 'frame53.jpg', 'frame47.jpg', 'frame51.jpg', 'frame45.jpg', 'frame44.jpg', 'frame50.jpg', 'frame54.jpg', 'frame40.jpg', 'frame41.jpg', 'frame55.jpg', 'frame43.jpg', 'frame57.jpg', 'frame56.jpg', 'frame42.jpg', 'frame19.jpg', 'frame25.jpg', 'frame31.jpg', 'frame30.jpg', 'frame24.jpg', 'frame18.jpg', 'frame32.jpg', 'frame26.jpg', 'frame27.jpg', 'frame33.jpg', 'frame37.jpg', 'frame23.jpg', 'frame22.jpg', 'frame36.jpg', 'frame20.jpg', 'frame34.jpg', 'frame9.jpg', 'frame8.jpg', 'frame35.jpg', 'frame21.jpg', 'frame38.jpg', 'frame5.jpg', 'frame10.jpg', 'frame11.jpg', 'frame4.jpg', 'frame39.jpg', 'frame6.jpg', 'frame13.jpg', 'frame12.jpg', 'frame7.jpg', 'frame3.jpg', 'frame16.jpg', 'frame17.jpg', 'frame2.jpg', 'frame0.jpg', 'frame15.jpg', 'frame29.jpg', 'frame28.jpg', 'frame14.jpg', 'frame1.jpg', 'frame66.jpg', 'frame58.jpg', 'frame64.jpg', 'frame65.jpg', 'frame59.jpg', 'frame61.jpg', 'frame49.jpg', 'frame48.jpg', 'frame60.jpg', 'frame62.jpg', 'frame63.jpg'] /Users/brinkley97/Documents/development/classes/csci_535_multimodal_probabilistic_learning/datasets/git_lfs/CREMA-D/sample_VideoFlash2/all_faces/1001_DFA_ANG_XX_frames_to_cropped_face/\n",
      "\n",
      "1001_DFA_SAD_XX_frames\n",
      "['.DS_Store'] /Users/brinkley97/Documents/development/classes/csci_535_multimodal_probabilistic_learning/datasets/git_lfs/CREMA-D/sample_VideoFlash2/all_faces/1001_DFA_SAD_XX_frames_to_cropped_face/\n",
      "\n",
      "1001_DFA_DIS_XX_frames\n",
      "['frame46.jpg', 'frame52.jpg', 'frame53.jpg', 'frame47.jpg', 'frame51.jpg', 'frame45.jpg', 'frame44.jpg', 'frame50.jpg', 'frame54.jpg', 'frame40.jpg', 'frame68.jpg', 'frame69.jpg', 'frame41.jpg', 'frame55.jpg', 'frame43.jpg', 'frame57.jpg', 'frame56.jpg', 'frame42.jpg', 'frame19.jpg', 'frame25.jpg', 'frame31.jpg', 'frame30.jpg', 'frame24.jpg', 'frame18.jpg', 'frame32.jpg', 'frame26.jpg', 'frame27.jpg', 'frame33.jpg', 'frame37.jpg', 'frame23.jpg', 'frame22.jpg', 'frame36.jpg', 'frame20.jpg', 'frame34.jpg', 'frame9.jpg', 'frame8.jpg', 'frame35.jpg', 'frame21.jpg', 'frame38.jpg', 'frame5.jpg', 'frame10.jpg', 'frame11.jpg', 'frame4.jpg', 'frame39.jpg', 'frame6.jpg', 'frame13.jpg', 'frame12.jpg', 'frame7.jpg', 'frame3.jpg', 'frame16.jpg', 'frame17.jpg', 'frame2.jpg', 'frame0.jpg', 'frame15.jpg', 'frame29.jpg', 'frame28.jpg', 'frame14.jpg', 'frame1.jpg', 'frame67.jpg', 'frame66.jpg', 'frame58.jpg', 'frame64.jpg', 'frame65.jpg', 'frame59.jpg', 'frame61.jpg', 'frame49.jpg', 'frame48.jpg', 'frame60.jpg', 'frame62.jpg', 'frame63.jpg'] /Users/brinkley97/Documents/development/classes/csci_535_multimodal_probabilistic_learning/datasets/git_lfs/CREMA-D/sample_VideoFlash2/all_faces/1001_DFA_DIS_XX_frames_to_cropped_face/\n",
      "\n",
      "1001_DFA_NEU_XX_frames\n",
      "['frame46.jpg', 'frame52.jpg', 'frame53.jpg', 'frame47.jpg', 'frame51.jpg', 'frame45.jpg', 'frame44.jpg', 'frame50.jpg', 'frame54.jpg', 'frame40.jpg', 'frame41.jpg', 'frame55.jpg', 'frame43.jpg', 'frame57.jpg', 'frame56.jpg', 'frame42.jpg', 'frame19.jpg', 'frame25.jpg', 'frame31.jpg', 'frame30.jpg', 'frame24.jpg', 'frame18.jpg', 'frame32.jpg', 'frame26.jpg', 'frame27.jpg', 'frame33.jpg', 'frame37.jpg', 'frame23.jpg', 'frame22.jpg', 'frame36.jpg', 'frame20.jpg', 'frame34.jpg', 'frame9.jpg', 'frame8.jpg', 'frame35.jpg', 'frame21.jpg', 'frame38.jpg', 'frame5.jpg', 'frame10.jpg', 'frame11.jpg', 'frame4.jpg', 'frame39.jpg', 'frame6.jpg', 'frame13.jpg', 'frame12.jpg', 'frame7.jpg', 'frame3.jpg', 'frame16.jpg', 'frame17.jpg', 'frame2.jpg', 'frame0.jpg', 'frame15.jpg', 'frame29.jpg', 'frame28.jpg', 'frame14.jpg', 'frame1.jpg', 'frame58.jpg', 'frame59.jpg', 'frame49.jpg', 'frame48.jpg', 'frame60.jpg'] /Users/brinkley97/Documents/development/classes/csci_535_multimodal_probabilistic_learning/datasets/git_lfs/CREMA-D/sample_VideoFlash2/all_faces/1001_DFA_NEU_XX_frames_to_cropped_face/\n",
      "\n",
      "1001_DFA_HAP_XX_frames\n",
      "['frame46.jpg', 'frame52.jpg', 'frame53.jpg', 'frame47.jpg', 'frame51.jpg', 'frame45.jpg', 'frame44.jpg', 'frame50.jpg', 'frame54.jpg', 'frame40.jpg', 'frame41.jpg', 'frame55.jpg', 'frame43.jpg', 'frame42.jpg', 'frame19.jpg', 'frame25.jpg', 'frame31.jpg', 'frame30.jpg', 'frame24.jpg', 'frame18.jpg', 'frame32.jpg', 'frame26.jpg', 'frame27.jpg', 'frame33.jpg', 'frame37.jpg', 'frame23.jpg', 'frame22.jpg', 'frame36.jpg', 'frame20.jpg', 'frame34.jpg', 'frame9.jpg', 'frame8.jpg', 'frame35.jpg', 'frame21.jpg', 'frame38.jpg', 'frame5.jpg', 'frame10.jpg', 'frame11.jpg', 'frame4.jpg', 'frame39.jpg', 'frame6.jpg', 'frame13.jpg', 'frame12.jpg', 'frame7.jpg', 'frame3.jpg', 'frame16.jpg', 'frame17.jpg', 'frame2.jpg', 'frame0.jpg', 'frame15.jpg', 'frame29.jpg', 'frame28.jpg', 'frame14.jpg', 'frame1.jpg', 'frame49.jpg', 'frame48.jpg'] /Users/brinkley97/Documents/development/classes/csci_535_multimodal_probabilistic_learning/datasets/git_lfs/CREMA-D/sample_VideoFlash2/all_faces/1001_DFA_HAP_XX_frames_to_cropped_face/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_video_path(CREMA_D_FRAMES_PATH, SAVE_CREMA_D_CROPPED_FRAMES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57f6e90-9a88-465b-ad87-b256689eaf7e",
   "metadata": {},
   "source": [
    "# MSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72a61c0a-e176-43d5-beee-5249ae0bd23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSP_DATASET_PATH = 'msp/videos/r_and_t_frames/'\n",
    "# MSP_DATASET_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6465baa-4ba0-4be6-841a-ef4cdd159ffc",
   "metadata": {},
   "source": [
    "## R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4df42fca-58fd-40b7-b15c-4fccdb339cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_FRAMES_PATH = BASE + CLASS_PATH + DATASET_PATH + MSP_DATASET_PATH + 'r_frames/'\n",
    "# R_FRAMES_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "491ea478-eed9-45dc-acdc-bf264dea5321",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_R_CROPPED_FRAMES_PATH = BASE + CLASS_PATH + DATASET_PATH + MSP_DATASET_PATH + 'face_r_frames/'\n",
    "# SAVE_R_CROPPED_FRAMES_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b02b59e-2c9f-43c4-a755-66e805203324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_video_path(R_FRAMES, SAVE_R_CROPPED_FRAMES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68e10ba-c018-444e-9b1a-070035b87577",
   "metadata": {},
   "source": [
    "## T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6dd4cc63-e3a4-4b01-a132-cdbcfd41b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_FRAMES_PATH = BASE + CLASS_PATH + DATASET_PATH + MSP_DATASET_PATH + 't_frames/'\n",
    "# T_FRAMES_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16dd4b14-213a-4466-9e85-afe715f650c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_T_CROPPED_FRAMES_PATH = BASE + CLASS_PATH + DATASET_PATH + MSP_DATASET_PATH + 'face_t_frames/'\n",
    "# SAVE_T_CROPPED_FRAMES_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a46cdd35-9464-486f-91ef-c133efb7c9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_video_path(T_FRAMES_PATH, SAVE_T_CROPPED_FRAMES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecc5f2e-e41f-48c6-b99a-2fc44e2fc708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
