{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aef6b48-080c-4d36-8c42-bb4f3d6a9c30",
   "metadata": {},
   "source": [
    "# HW 2 Multimodal Machine Learning for Emotion Recognition\n",
    "\n",
    "- main (this notebook) with sub notebooks\n",
    "    1. audio (acoustic)\n",
    "    2. text (lexical)\n",
    "    3. visual\n",
    "- IEMOCAP (Interactive Emotional Dyadic Motion Capture) database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363ed91f-14a4-4ca3-8ee8-f3546c5d67d6",
   "metadata": {},
   "source": [
    "# TODOs\n",
    "In the file dataset.csv, you are provided with the relative address for the audio, visual and text feature files alongwith their corresponding emotion labels. There are 5 sessions and each session has one male and one female speaker.\n",
    "\n",
    "1. You can use different pooling methods (e.g., max pooling, mean pooling) for reducing the temporal dimensionof the audio and visual files, or use your preferred temporal modeling (e.g., RNN, GRU, LSTM) to obtainfeature vectors per data point.1\n",
    "\n",
    "2. Perform a 4-class emotion classification using your preferred classifier with the obtained feature vectors. Selectthe parameters using Grid Search (search over a range for hyper-parameters). Perform any additional stepsyou see fit to obtain the best results.\n",
    "\n",
    "3. Report your classification results on individual modalities (vision, speech, and text) using F1-micro metricon a 10-fold subject-independent cross validation.\n",
    "\n",
    "4. How do you handle the problem of class imbalance? Plot the confusion matrix for the 4 classes.\n",
    "\n",
    "5. Use both early fusion (concatenate features from different modalities) and late fusion (majority vote over theoutputs of the unimodal models) to obtain multimodal classification results. Report and compare the resultsfor both fusion techniques.\n",
    "\n",
    "6. Provide an interpretation on your results from the performed unimodal and multimodal classification tasks.Which one is performing best and why?\n",
    "\n",
    "*Note*: You are only allowed to use the features and labels provided by us with this assignment. Please refrainfrom using the original data; assignments submitted with any other labels or data will not be graded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3496762d-0e98-4562-b1b6-0ba40eb442aa",
   "metadata": {},
   "source": [
    "#  Imports + Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05fcbf4a-2978-4d3d-91d6-817f606446c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4b7f251-4c3d-4a0e-ae22-07d27bffb72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all subnotebooks\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa, librosa.display\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# for audio - maybe store in specific notebook?\n",
    "import skimage.measure\n",
    "\n",
    "# for text\n",
    "\n",
    "# for visual\n",
    "import ipympl as mpl # to show (image) plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c7727a-20df-426a-8440-ba502c7575c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"/Users/brinkley97/Documents/development/\"\n",
    "CLASS_PATH = \"classes/csci_535_multimodal_probabilistic_learning/\"\n",
    "DATASET_PATH = \"datasets/hw_2\"\n",
    "\n",
    "SESSION_1 = \"Session1/\"\n",
    "SESSION_2 = \"Session2\"\n",
    "SESSION_3 = \"Session3/\"\n",
    "SESSION_4 = \"Session4/\"\n",
    "SESSION_5 = \"Session5/\"\n",
    "\n",
    "SES_01F = \"Ses01F_impro01/\"\n",
    "\n",
    "FILE = \"/iemocapRelativeAddressForFiles.csv\"\n",
    "file_paths = BASE + CLASS_PATH + DATASET_PATH + FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6d995c9-e0a3-48fe-a337-a8db4cb64a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    original_data = pd.read_csv(file)\n",
    "    # original_data = pd.DataFrame(file)\n",
    "    copy_of_data = original_data.copy()\n",
    "    return copy_of_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d7f56b7-2cf6-45b2-8b70-fea26b7e0702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name_list</th>\n",
       "      <th>speakers</th>\n",
       "      <th>visual_features</th>\n",
       "      <th>acoustic_features</th>\n",
       "      <th>lexical_features</th>\n",
       "      <th>emotion_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ses01F_impro01_F001</td>\n",
       "      <td>F01</td>\n",
       "      <td>/features/visual_features/Session1/Ses01F_impr...</td>\n",
       "      <td>/features/acoustic_features/Session1/Ses01F_im...</td>\n",
       "      <td>/features/lexical_features/Session1/Ses01F_imp...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ses01F_impro01_M011</td>\n",
       "      <td>M01</td>\n",
       "      <td>/features/visual_features/Session1/Ses01F_impr...</td>\n",
       "      <td>/features/acoustic_features/Session1/Ses01F_im...</td>\n",
       "      <td>/features/lexical_features/Session1/Ses01F_imp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ses01F_impro02_F002</td>\n",
       "      <td>F01</td>\n",
       "      <td>/features/visual_features/Session1/Ses01F_impr...</td>\n",
       "      <td>/features/acoustic_features/Session1/Ses01F_im...</td>\n",
       "      <td>/features/lexical_features/Session1/Ses01F_imp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ses01F_impro02_F003</td>\n",
       "      <td>F01</td>\n",
       "      <td>/features/visual_features/Session1/Ses01F_impr...</td>\n",
       "      <td>/features/acoustic_features/Session1/Ses01F_im...</td>\n",
       "      <td>/features/lexical_features/Session1/Ses01F_imp...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ses01F_impro02_F004</td>\n",
       "      <td>F01</td>\n",
       "      <td>/features/visual_features/Session1/Ses01F_impr...</td>\n",
       "      <td>/features/acoustic_features/Session1/Ses01F_im...</td>\n",
       "      <td>/features/lexical_features/Session1/Ses01F_imp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>Ses05M_script03_2_M029</td>\n",
       "      <td>M05</td>\n",
       "      <td>/features/visual_features/Session5/Ses05M_scri...</td>\n",
       "      <td>/features/acoustic_features/Session5/Ses05M_sc...</td>\n",
       "      <td>/features/lexical_features/Session5/Ses05M_scr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>Ses05M_script03_2_M039</td>\n",
       "      <td>M05</td>\n",
       "      <td>/features/visual_features/Session5/Ses05M_scri...</td>\n",
       "      <td>/features/acoustic_features/Session5/Ses05M_sc...</td>\n",
       "      <td>/features/lexical_features/Session5/Ses05M_scr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>Ses05M_script03_2_M041</td>\n",
       "      <td>M05</td>\n",
       "      <td>/features/visual_features/Session5/Ses05M_scri...</td>\n",
       "      <td>/features/acoustic_features/Session5/Ses05M_sc...</td>\n",
       "      <td>/features/lexical_features/Session5/Ses05M_scr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>Ses05M_script03_2_M042</td>\n",
       "      <td>M05</td>\n",
       "      <td>/features/visual_features/Session5/Ses05M_scri...</td>\n",
       "      <td>/features/acoustic_features/Session5/Ses05M_sc...</td>\n",
       "      <td>/features/lexical_features/Session5/Ses05M_scr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>Ses05M_script03_2_M043</td>\n",
       "      <td>M05</td>\n",
       "      <td>/features/visual_features/Session5/Ses05M_scri...</td>\n",
       "      <td>/features/acoustic_features/Session5/Ses05M_sc...</td>\n",
       "      <td>/features/lexical_features/Session5/Ses05M_scr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1336 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              file_name_list speakers  \\\n",
       "0        Ses01F_impro01_F001      F01   \n",
       "1        Ses01F_impro01_M011      M01   \n",
       "2        Ses01F_impro02_F002      F01   \n",
       "3        Ses01F_impro02_F003      F01   \n",
       "4        Ses01F_impro02_F004      F01   \n",
       "...                      ...      ...   \n",
       "1331  Ses05M_script03_2_M029      M05   \n",
       "1332  Ses05M_script03_2_M039      M05   \n",
       "1333  Ses05M_script03_2_M041      M05   \n",
       "1334  Ses05M_script03_2_M042      M05   \n",
       "1335  Ses05M_script03_2_M043      M05   \n",
       "\n",
       "                                        visual_features  \\\n",
       "0     /features/visual_features/Session1/Ses01F_impr...   \n",
       "1     /features/visual_features/Session1/Ses01F_impr...   \n",
       "2     /features/visual_features/Session1/Ses01F_impr...   \n",
       "3     /features/visual_features/Session1/Ses01F_impr...   \n",
       "4     /features/visual_features/Session1/Ses01F_impr...   \n",
       "...                                                 ...   \n",
       "1331  /features/visual_features/Session5/Ses05M_scri...   \n",
       "1332  /features/visual_features/Session5/Ses05M_scri...   \n",
       "1333  /features/visual_features/Session5/Ses05M_scri...   \n",
       "1334  /features/visual_features/Session5/Ses05M_scri...   \n",
       "1335  /features/visual_features/Session5/Ses05M_scri...   \n",
       "\n",
       "                                      acoustic_features  \\\n",
       "0     /features/acoustic_features/Session1/Ses01F_im...   \n",
       "1     /features/acoustic_features/Session1/Ses01F_im...   \n",
       "2     /features/acoustic_features/Session1/Ses01F_im...   \n",
       "3     /features/acoustic_features/Session1/Ses01F_im...   \n",
       "4     /features/acoustic_features/Session1/Ses01F_im...   \n",
       "...                                                 ...   \n",
       "1331  /features/acoustic_features/Session5/Ses05M_sc...   \n",
       "1332  /features/acoustic_features/Session5/Ses05M_sc...   \n",
       "1333  /features/acoustic_features/Session5/Ses05M_sc...   \n",
       "1334  /features/acoustic_features/Session5/Ses05M_sc...   \n",
       "1335  /features/acoustic_features/Session5/Ses05M_sc...   \n",
       "\n",
       "                                       lexical_features  emotion_labels  \n",
       "0     /features/lexical_features/Session1/Ses01F_imp...               3  \n",
       "1     /features/lexical_features/Session1/Ses01F_imp...               0  \n",
       "2     /features/lexical_features/Session1/Ses01F_imp...               1  \n",
       "3     /features/lexical_features/Session1/Ses01F_imp...               3  \n",
       "4     /features/lexical_features/Session1/Ses01F_imp...               1  \n",
       "...                                                 ...             ...  \n",
       "1331  /features/lexical_features/Session5/Ses05M_scr...               0  \n",
       "1332  /features/lexical_features/Session5/Ses05M_scr...               0  \n",
       "1333  /features/lexical_features/Session5/Ses05M_scr...               0  \n",
       "1334  /features/lexical_features/Session5/Ses05M_scr...               0  \n",
       "1335  /features/lexical_features/Session5/Ses05M_scr...               0  \n",
       "\n",
       "[1336 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 classes - anger(0), sadness(1) and happiness(2),and neutral(3)\n",
    "dataset_paths_copy = load_data(file_paths)\n",
    "dataset_paths_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953b418a-a88f-42f5-bcc3-b5f24b41dd67",
   "metadata": {},
   "source": [
    "# Preprocessing Files\n",
    "\n",
    "- [x] Build paths to specific files\n",
    "- [ ] Reduce the time (temporal) dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9666f957-8823-4533-9904-bace91e5bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_paths_to_file(df_with_paths, specific_feature):\n",
    "    \"\"\"With the given DataFrame of paths, build my paths...\n",
    "    \n",
    "    Parameters:\n",
    "    df_with_paths -- \n",
    "    specific_feature -- str (either visual_features, acoustic_features, or lexical_features)\n",
    "    \n",
    "    Return:\n",
    "    list\n",
    "    \"\"\"\n",
    "    \n",
    "    features = df_with_paths.loc[0:, ['file_name_list', 'speakers', specific_feature]]\n",
    "    features_path = features.loc[0:, specific_feature]\n",
    "    features[\"file_with_path\"] = BASE + CLASS_PATH + DATASET_PATH + features_path\n",
    "    list_of_features = list(features[\"file_with_path\"])\n",
    "    \n",
    "    return list_of_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5afb5d8d-fe02-46e0-8d78-2476373f2067",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_feature = 'acoustic_features'\n",
    "audio_features_paths = build_paths_to_file(dataset_paths_copy, specific_feature)\n",
    "\n",
    "specific_feature = 'lexical_features'\n",
    "text_features_paths = build_paths_to_file(dataset_paths_copy, specific_feature)\n",
    "\n",
    "\n",
    "specific_feature = 'visual_features'\n",
    "visual_features_paths = build_paths_to_file(dataset_paths_copy, specific_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c326259-376f-4b2f-bb0d-81cb37cda63a",
   "metadata": {},
   "source": [
    "## Load Audio (Acoustic) features\n",
    "- We have VGGish, a deep convolutional neural network pre-trained on audio spectrograms extracted from a large database of videos to recognize a large variety of audio event categories [3]. The 128-dimensional embeddings were generated by VGGish after dimensionality reduction with Principal Component Analysis (PCA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b46385e-2c88-46bd-b403-d94573a7ead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_features_path = BASE + CLASS_PATH + DATASET_PATH + '/features/acoustic_features/' + SESSION_1 + SES_01F\n",
    "# # audio_features\n",
    "# female_s1 = audio_features_path + 'Ses01F_impro01_F001.npy'\n",
    "# male_s1 = audio_features_path + 'Ses01F_impro01_M011.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feafd7bb-f087-4256-87bb-696c545179ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# female_s1_load = np.load(female_s1)\n",
    "# male_s1_load = np.load(male_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eb940e7-a9bc-4d91-bd82-54c415e318e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_features_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17468330-a14a-46b3-9392-e0055d6a4e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resampled_audio_features_path = BASE + CLASS_PATH + DATASET_PATH + '/resampled_features/test_save_features/' + SESSION_1 + SES_01F\n",
    "resampled_audio_features_path = BASE + CLASS_PATH + DATASET_PATH + '/resampled_features/test_save_features/'\n",
    "# resampled_audio_features_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4578af-7680-4b9f-9c25-179ca718fd6e",
   "metadata": {},
   "source": [
    "## Load Text (Lexical) features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5253c507-358b-409d-9ba9-1372626296fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2563c90-3d8b-4548-9fd1-821baa2f3921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda8b732-2a56-4140-89b9-a07b5e4d083d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee403c76-babd-447c-886c-04aa6538b6fd",
   "metadata": {},
   "source": [
    "## Load Visual features\n",
    "\n",
    "- For the visual features, we have face embeddings obtained from a ResNet model [4] pre-trained on ImageNet. We have $ T Ã— 2048 $ matrix for each utterance, where $ T $ denotes the number of frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f408b6a6-c07f-4926-ade5-ac1245cb7992",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_features_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008aea47-edca-46d6-8edd-93636d6b6408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
