{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97411522-fe15-42e5-994e-43b1d2d4f22f",
   "metadata": {},
   "source": [
    "# XAI Recipes for the HuggingFace ðŸ¤— Image Classification Models\n",
    "# ![DFF](https://raw.githubusercontent.com/jacobgil/pytorch-grad-cam/master/tutorials/huggingface_dff.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c070715-41b9-437c-8932-3263671291d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch-gradcam\n",
    "# !pip install git+https://github.com/jacobgil/pytorch-grad-cam.git\n",
    "# !git lfs clone https://github.com/jacobgil/pytorch-grad-cam.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "896f02d8-bea0-4e70-b96d-826f5e89b78c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deep_feature_factorization'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# for run_dff_on_image\u001b[39;00m\n\u001b[1;32m      7\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/brinkley97/Documents/development/classes/csci_535_multimodal_probabilistic_learning/play/pytorch-grad-cam/pytorch_grad_cam/feature_factorization\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdeep_feature_factorization\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# for ClassifierOutputTarget\u001b[39;00m\n\u001b[1;32m     11\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/brinkley97/Documents/development/classes/csci_535_multimodal_probabilistic_learning/play/pytorch-grad-cam/pytorch_grad_cam/utils/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deep_feature_factorization'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "\n",
    "# for run_dff_on_image\n",
    "sys.path.insert(1, '/Users/brinkley97/Documents/development/classes/csci_535_multimodal_probabilistic_learning/play/pytorch-grad-cam/pytorch_grad_cam/feature_factorization')\n",
    "import deep_feature_factorization\n",
    "\n",
    "# for ClassifierOutputTarget\n",
    "sys.path.insert(1, '/Users/brinkley97/Documents/development/classes/csci_535_multimodal_probabilistic_learning/play/pytorch-grad-cam/pytorch_grad_cam/utils/')\n",
    "import model_targets\n",
    "\n",
    "sys.path.insert(1, '/Users/brinkley97/Documents/development/classes/csci_535_multimodal_probabilistic_learning/play/pytorch-grad-cam/pytorch_grad_cam/')\n",
    "import base_cam\n",
    "\n",
    "import image\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from gradcam import GradCAM\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "from typing import List, Callable, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a969be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"huggingface/cats-image\")\n",
    "image = dataset[\"test\"][\"image\"][0]\n",
    "img_tensor = transforms.ToTensor()(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a9ecb-4c47-4538-8480-d6299feafa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Model wrapper to return a tensor\"\"\"\n",
    "class HuggingfaceToTensorModelWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(HuggingfaceToTensorModelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3112b2c7-2fff-4ac9-a4f7-79e13867121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Translate the category name to the category index.\n",
    "    Some models aren't trained on Imagenet but on even larger datasets,\n",
    "    so we can't just assume that 761 will always be remote-control.\n",
    "\n",
    "\"\"\"\n",
    "def category_name_to_index(model, category_name):\n",
    "    name_to_index = dict((v, k) for k, v in model.config.id2label.items())\n",
    "    return name_to_index[category_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b071f62-763e-4001-9838-e0ac479982a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Helper function to run GradCAM on an image and create a visualization.\n",
    "    (note to myself: this is probably useful enough to move into the package)\n",
    "    If several targets are passed in targets_for_gradcam,\n",
    "    e.g different categories,\n",
    "    a visualization for each of them will be created.\n",
    "    \n",
    "# \"\"\"\n",
    "# def run_grad_cam_on_image(model: torch.nn.Module,\n",
    "#                           target_layer: torch.nn.Module,\n",
    "#                           targets_for_gradcam: List[Callable],\n",
    "#                           reshape_transform: Optional[Callable],\n",
    "#                           input_tensor: torch.nn.Module=img_tensor,\n",
    "#                           input_image: Image=image,\n",
    "#                           method: Callable=GradCAM):\n",
    "#     with method(model=HuggingfaceToTensorModelWrapper(model),\n",
    "#                  target_layers=[target_layer],\n",
    "#                  reshape_transform=reshape_transform) as cam:\n",
    "\n",
    "#         # Replicate the tensor for each of the categories we want to create Grad-CAM for:\n",
    "#         repeated_tensor = input_tensor[None, :].repeat(len(targets_for_gradcam), 1, 1, 1)\n",
    "\n",
    "#         batch_results = cam(input_tensor=repeated_tensor,\n",
    "#                             targets=targets_for_gradcam)\n",
    "#         results = []\n",
    "#         for grayscale_cam in batch_results:\n",
    "#             visualization = image.show_cam_on_image(np.float32(input_image)/255,\n",
    "#                                               grayscale_cam,\n",
    "#                                               use_rgb=True)\n",
    "#             # Make it weight less in the notebook:\n",
    "#             visualization = cv2.resize(visualization,\n",
    "#                                        (visualization.shape[1]//2, visualization.shape[0]//2))\n",
    "#             results.append(visualization)\n",
    "#         return np.hstack(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eb731b-fe11-4315-92e5-84dce607b7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_categories(model, img_tensor, top_k=5):\n",
    "    logits = model(img_tensor.unsqueeze(0)).logits\n",
    "    indices = logits.cpu()[0, :].detach().numpy().argsort()[-top_k :][::-1]\n",
    "    for i in indices:\n",
    "        print(f\"Predicted class {i}: {model.config.id2label[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d3e305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ResNetForImageClassification\n",
    "model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
    "\n",
    "# We will show GradCAM for the \"Egyptian Cat\" and the 'Remote Control\" categories:\n",
    "targets_for_gradcam = [model_targets.ClassifierOutputTarget(category_name_to_index(model, \"Egyptian cat\")),\n",
    "                       model_targets.ClassifierOutputTarget(category_name_to_index(model, \"remote control, remote\"))]\n",
    "\n",
    "# The last layer in the Resnet Encoder:\n",
    "target_layer = model.resnet.encoder.stages[-1].layers[-1]\n",
    "\n",
    "display(Image.fromarray(deep_feature_factorization.run_dff_on_image(model=model,\n",
    "                          target_layer=target_layer,\n",
    "                          classifier=model.classifier,\n",
    "                          img_pil=image,\n",
    "                          img_tensor=img_tensor,\n",
    "                          reshape_transform=None,\n",
    "                          n_components=4,\n",
    "                          top_k=2)))\n",
    "# display(Image.fromarray(run_grad_cam_on_image(model=model,\n",
    "#                       target_layer=target_layer,\n",
    "#                       targets_for_gradcam=targets_for_gradcam,\n",
    "#                       reshape_transform=None)))\n",
    "print_top_categories(model, img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8540ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "def reshape_transform_vit_huggingface(x):\n",
    "    activations = x[:, 1:, :]\n",
    "    activations = activations.view(activations.shape[0],\n",
    "                                   12, 12, activations.shape[2])\n",
    "    activations = activations.transpose(2, 3).transpose(1, 2)\n",
    "    return activations\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-large-patch32-384')\n",
    "targets_for_gradcam = [model_targets.ClassifierOutputTarget(category_name_to_index(model, \"Egyptian cat\")),\n",
    "                       model_targets.ClassifierOutputTarget(category_name_to_index(model, \"remote control, remote\"))]\n",
    "target_layer_dff = model.vit.layernorm\n",
    "target_layer_gradcam = model.vit.encoder.layer[-2].output\n",
    "image_resized = image.resize((384, 384))\n",
    "tensor_resized = transforms.ToTensor()(image_resized)\n",
    "\n",
    "\n",
    "display(Image.fromarray(deep_feature_factorization.run_dff_on_image(model=model,\n",
    "                          target_layer=target_layer_dff,\n",
    "                          classifier=model.classifier,\n",
    "                          img_pil=image_resized,\n",
    "                          img_tensor=tensor_resized,\n",
    "                          reshape_transform=reshape_transform_vit_huggingface,\n",
    "                          n_components=4,\n",
    "                          top_k=2)))\n",
    "display(Image.fromarray(run_grad_cam_on_image(model=model,\n",
    "                      target_layer=target_layer_gradcam,\n",
    "                      targets_for_gradcam=targets_for_gradcam,\n",
    "                      input_tensor=tensor_resized,\n",
    "                      input_image=image_resized,\n",
    "                      reshape_transform=reshape_transform_vit_huggingface)))\n",
    "print_top_categories(model, tensor_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ec7397-50fd-4238-9fcc-b19b66b67f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
