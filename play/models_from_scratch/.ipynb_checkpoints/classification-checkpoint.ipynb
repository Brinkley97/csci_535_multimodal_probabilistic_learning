{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85b9070d-3847-4d79-ba45-620050bc07c6",
   "metadata": {},
   "source": [
    "# Classification of ViT Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8df78bc6-de51-48a9-8c98-529405b1d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99274f48-a2eb-4f8a-adc0-6f4a110c3b89",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da1ec6de-18da-4303-b1c1-3b8e40d8d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = '/Users/brinkley97/Documents/development/'\n",
    "CLASS_PATH = 'classes/csci_535_multimodal_probabilistic_learning/'\n",
    "DATASET_PATH = 'datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cf24e9a-b04b-4380-b58f-929dbd72e325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    original_data = pd.read_csv(file)\n",
    "    # original_data = pd.DataFrame(file)\n",
    "    copy_of_data = original_data.copy()\n",
    "    return copy_of_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6416ed1-e41c-429f-897e-5102c2d541d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_crema_d_features = BASE + CLASS_PATH + DATASET_PATH + 'git_lfs/CREMA-D/sample_VideoFlash/' + 'crema_d_extracted_features_v1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1332d2f4-62e0-4e64-a0b9-5d686380873d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder Name</th>\n",
       "      <th>Tensor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_DFA_HAP_XX_frames_to_cropped_face</td>\n",
       "      <td>tensor([[[ 0.1296,  0.1780, -0.1627,  ..., -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001_DFA_ANG_XX_frames_to_cropped_face</td>\n",
       "      <td>tensor([[[ 0.1938,  0.2272, -0.2053,  ..., -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001_DFA_NEU_XX_frames_to_cropped_face</td>\n",
       "      <td>tensor([[[ 0.1753,  0.2366, -0.1398,  ..., -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001_DFA_SAD_XX_frames_to_cropped_face</td>\n",
       "      <td>tensor([[[ 1.6332e-01,  1.9916e-01, -1.7832e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001_DFA_HAP_XX_frames_to_cropped_face</td>\n",
       "      <td>tensor([[[ 0.1296,  0.1780, -0.1627,  ..., -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1001_DFA_DIS_XX_frames_to_cropped_face</td>\n",
       "      <td>tensor([[[ 0.2035,  0.1389, -0.2247,  ..., -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1001_DFA_ANG_XX_frames_to_cropped_face</td>\n",
       "      <td>tensor([[[ 0.1938,  0.2272, -0.2053,  ..., -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1001_DFA_FEA_XX_frames_to_cropped_face</td>\n",
       "      <td>tensor([[[ 0.1829,  0.1679, -0.1665,  ..., -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1001_DFA_SAD_XX_frames_to_cropped_face</td>\n",
       "      <td>tensor([[[ 1.6332e-01,  1.9916e-01, -1.7832e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1001_DFA_DIS_XX_frames_to_cropped_face</td>\n",
       "      <td>tensor([[[ 0.2035,  0.1389, -0.2247,  ..., -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1001_DFA_ANG_XX_frames_to_cropped_face</td>\n",
       "      <td>tensor([[[ 0.1938,  0.2272, -0.2053,  ..., -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1001_DFA_FEA_XX_frames_to_cropped_face</td>\n",
       "      <td>tensor([[[ 0.1829,  0.1679, -0.1665,  ..., -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Folder Name  \\\n",
       "0   1001_DFA_HAP_XX_frames_to_cropped_face   \n",
       "1   1001_DFA_ANG_XX_frames_to_cropped_face   \n",
       "2   1001_DFA_NEU_XX_frames_to_cropped_face   \n",
       "3   1001_DFA_SAD_XX_frames_to_cropped_face   \n",
       "4   1001_DFA_HAP_XX_frames_to_cropped_face   \n",
       "5   1001_DFA_DIS_XX_frames_to_cropped_face   \n",
       "6   1001_DFA_ANG_XX_frames_to_cropped_face   \n",
       "7   1001_DFA_FEA_XX_frames_to_cropped_face   \n",
       "8   1001_DFA_SAD_XX_frames_to_cropped_face   \n",
       "9   1001_DFA_DIS_XX_frames_to_cropped_face   \n",
       "10  1001_DFA_ANG_XX_frames_to_cropped_face   \n",
       "11  1001_DFA_FEA_XX_frames_to_cropped_face   \n",
       "\n",
       "                                               Tensor  \n",
       "0   tensor([[[ 0.1296,  0.1780, -0.1627,  ..., -0....  \n",
       "1   tensor([[[ 0.1938,  0.2272, -0.2053,  ..., -0....  \n",
       "2   tensor([[[ 0.1753,  0.2366, -0.1398,  ..., -0....  \n",
       "3   tensor([[[ 1.6332e-01,  1.9916e-01, -1.7832e-0...  \n",
       "4   tensor([[[ 0.1296,  0.1780, -0.1627,  ..., -0....  \n",
       "5   tensor([[[ 0.2035,  0.1389, -0.2247,  ..., -0....  \n",
       "6   tensor([[[ 0.1938,  0.2272, -0.2053,  ..., -0....  \n",
       "7   tensor([[[ 0.1829,  0.1679, -0.1665,  ..., -0....  \n",
       "8   tensor([[[ 1.6332e-01,  1.9916e-01, -1.7832e-0...  \n",
       "9   tensor([[[ 0.2035,  0.1389, -0.2247,  ..., -0....  \n",
       "10  tensor([[[ 0.1938,  0.2272, -0.2053,  ..., -0....  \n",
       "11  tensor([[[ 0.1829,  0.1679, -0.1665,  ..., -0....  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crema_d_extracted_features_copy = load_data(path_to_crema_d_features)\n",
    "crema_d_extracted_features_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72c222f1-1154-47ea-a924-04e5d8d04d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1001_DFA_HAP_XX_frames_to_cropped_face',\n",
       " '1001_DFA_ANG_XX_frames_to_cropped_face',\n",
       " '1001_DFA_NEU_XX_frames_to_cropped_face',\n",
       " '1001_DFA_SAD_XX_frames_to_cropped_face',\n",
       " '1001_DFA_HAP_XX_frames_to_cropped_face',\n",
       " '1001_DFA_DIS_XX_frames_to_cropped_face',\n",
       " '1001_DFA_ANG_XX_frames_to_cropped_face',\n",
       " '1001_DFA_FEA_XX_frames_to_cropped_face',\n",
       " '1001_DFA_SAD_XX_frames_to_cropped_face',\n",
       " '1001_DFA_DIS_XX_frames_to_cropped_face',\n",
       " '1001_DFA_ANG_XX_frames_to_cropped_face',\n",
       " '1001_DFA_FEA_XX_frames_to_cropped_face']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_label_folders = list(crema_d_extracted_features_copy.loc[0:, 'Folder Name'])\n",
    "emotion_label_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4099ee06-a8df-42bf-a5dd-4a586691d2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 09:45:00.161717: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%run 'extractingFeaturesWithViT.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "928aaa7c-24c6-40e3-915d-e9f6244d9438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe_crema_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf59e95-49a0-4644-98f5-1e5f96053d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_of_files = list(file_with_fe_crema_d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8f0a7c-ddd3-45cf-b356-5b8c2d94e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "crema_d_emotion_labels = ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']\n",
    "# crema_d_emotion_label_series = pd.Series(crema_d_emotion_labels)\n",
    "# crema_d_extracted_features_copy[crema_d_emotion_label_series] = 0\n",
    "# crema_d_extracted_features_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f843b63d-1753-4308-8ed8-9705d6c35cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "crema_d_true_labels = ['True Labels']\n",
    "crema_d_emotion_label_series = pd.Series(crema_d_true_labels)\n",
    "crema_d_extracted_features_copy[crema_d_emotion_label_series] = 0\n",
    "crema_d_extracted_features_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da99c3a7-a797-4d1c-9532-39ac9aa48cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_emotion_label = []\n",
    "for emotion_label_folder in emotion_label_folders:\n",
    "    # print(emotion_label_folder)\n",
    "\n",
    "    get_sub_strings = emotion_label_folder.split('_')\n",
    "    print(get_sub_strings)\n",
    "    \n",
    "    for get_sub_string in get_sub_strings:\n",
    "        \n",
    "        crema_d_extracted_features_copy['True Labels'] = get_sub_string\n",
    "        if get_sub_string in crema_d_emotion_labels:\n",
    "            print(get_sub_string)\n",
    "            save_emotion_label.append(get_sub_string)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e914df6-ed80-46c2-b385-c2ba4910fdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_emotion_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dd7c83-7095-4e4b-bf1d-c0e93bede557",
   "metadata": {},
   "outputs": [],
   "source": [
    "crema_d_extracted_features_copy['True Labels'] = save_emotion_label\n",
    "crema_d_extracted_features_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1191b94-5704-40c4-8a5c-9026959aac07",
   "metadata": {},
   "source": [
    "## STOP \n",
    "`ensure labels are matching folder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee56c3b-8439-4af0-99ab-0ccebdf9effe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_extracted_features(specific_dataset):\n",
    "    '''Convert from torch tensor to numpy array, then pool numpy array\n",
    "    \n",
    "    Parameters: \n",
    "    specific_dataset -- py list (with tensor torches as the elements)\n",
    "    \n",
    "    Return:\n",
    "    reduced_features -- py list (with numpy arrays as the elements)\n",
    "    '''\n",
    "    \n",
    "    stored_extracted_features = []\n",
    "    for tensor in fe_crema_d:\n",
    "        # print(type(tensor))\n",
    "        tensor_to_numpy = tensor.detach().numpy()\n",
    "        stored_extracted_features.append(tensor_to_numpy)\n",
    "\n",
    "    reduced_features = []\n",
    "    for stored_extracted_feature in stored_extracted_features:\n",
    "        # print(stored_extracted_feature)\n",
    "        resampled_features = np.mean(stored_extracted_feature, axis=0)\n",
    "        # print(resampled_features)\n",
    "        reduced_features.append(resampled_features)\n",
    "    return reduced_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb19ce8b-89f5-4ff1-b229-82a1b0827bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "crema_d_pooled_features = pool_extracted_features(fe_crema_d)\n",
    "# crema_d_pooled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74ab4d1-e509-4db9-8fb3-55563f813313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(specific_features, specific_features_true_labels):\n",
    "    \"\"\"Split data into TRAIN, TEST, and VALIDATION sets\n",
    "    \n",
    "    Parameters:\n",
    "    specific_features -- list (of the reduced features)\n",
    "    \n",
    "    Return:\n",
    "    X_train, X_test, X_val, y_train, y_test, y_val -- list (for that specific subset of the features)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(specific_features, specific_features_true_labels, test_size=0.4, random_state=42)\n",
    "    total_X = len(X_train) + len(X_test)\n",
    "    total_Y = len(y_train) + len(y_test)\n",
    "    \n",
    "    print(\"[INFO] X, y TRAIN sets\")\n",
    "    print(np.shape(X_train), np.shape(y_train))\n",
    "    \n",
    "    print(\"\\n[INFO] X, y TEST sets\")\n",
    "    print(np.shape(X_test), np.shape(y_test))\n",
    "    # print(\"[INFO] TOTAL TRAIN, TEST sets\")\n",
    "    # print(total_X, total_Y)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.4, random_state=42)\n",
    "    total_X = len(X_train) + len(X_val)\n",
    "    total_Y = len(y_train) + len(y_val)\n",
    "    \n",
    "    print(\"\\n[INFO] X, y TRAIN sets\")\n",
    "    print(np.shape(X_train), np.shape(y_train))\n",
    "    \n",
    "    print(\"\\n[INFO] X, y VALIDATION sets\")\n",
    "    print(np.shape(X_val), np.shape(y_val))\n",
    "\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4de6c75-a654-4886-ad02-9360c71a29f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels_crema_d = list(crema_d_extracted_features_copy.loc[0:, 'True Labels'])\n",
    "true_labels_crema_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3f55a2-ddc5-429c-bde4-fed6a075d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text, X_test_text, X_val_text, y_train_text, y_test_text, y_val_text = split_data(crema_d_pooled_features, true_labels_crema_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e399e8c2-cbe9-442e-98e2-aa7b77ed2319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0fc38f-9fec-4b57-b6b0-073fdebb92ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
