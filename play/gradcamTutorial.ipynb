{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca35797a-0030-43cc-9d10-b658031644a6",
   "metadata": {},
   "source": [
    "# Implementing Grad-CAM in PyTorch Tutorial\n",
    "\n",
    "https://medium.com/@stepanulyanin/implementing-grad-cam-in-pytorch-ea0937c31e82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dc843af-91ea-4e93-8abc-c9fb51388fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils import data\n",
    "from torchvision.models import vgg19\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c218da-b2d5-4dff-bc0a-a28c0bc31901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brinkley97/Documents/development/classes/csci_535_multimodal_probabilistic_learning/datasets/grad_cam_sample/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE = '/Users/brinkley97/Documents/development/'\n",
    "CLASS_PATH = 'classes/csci_535_multimodal_probabilistic_learning/'\n",
    "DATASET_PATH = 'datasets/'\n",
    "GRAD_CAM = 'grad_cam_sample/'\n",
    "PATH_TO_IMAGES = BASE + CLASS_PATH + DATASET_PATH + GRAD_CAM\n",
    "PATH_TO_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7be5f722-babf-462f-97b9-e7b29a398cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the ImageNet transformation\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)), \n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# define a 1 image dataset\n",
    "dataset = datasets.ImageFolder(root=PATH_TO_IMAGES, transform=transform)\n",
    "\n",
    "# define the dataloader to load that single image\n",
    "dataloader = data.DataLoader(dataset=dataset, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "752c5092-6d86-410e-b76b-8c780145b22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        \n",
    "        # get the pretrained VGG19 network\n",
    "        self.vgg = vgg19(pretrained=True)\n",
    "        \n",
    "        # disect the network to access its last convolutional layer\n",
    "        self.features_conv = self.vgg.features[:36]\n",
    "        \n",
    "        \n",
    "        # get the max pool of the features stem\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        \n",
    "        # get the classifier of the vgg19\n",
    "        self.classifier = self.vgg.classifier\n",
    "        \n",
    "        # placeholder for the gradients\n",
    "        self.gradients = None\n",
    "    \n",
    "    # hook for the gradients of the activations\n",
    "    def activations_hook(self, grad):\n",
    "        self.gradients = grad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features_conv(x)\n",
    "        \n",
    "        # register the hook\n",
    "        h = x.register_hook(self.activations_hook)\n",
    "        \n",
    "        # apply the remaining pooling\n",
    "        x = self.max_pool(x)\n",
    "        x = x.view((1, -1))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    # method for the gradient extraction\n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "    \n",
    "    # method for the activation exctraction\n",
    "    def get_activations(self, x):\n",
    "        return self.features_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a09c480-6901-46fa-99e1-f28bc20df99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brinkley97/opt/anaconda3/envs/emotion_rec_from_audiovisual/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/brinkley97/opt/anaconda3/envs/emotion_rec_from_audiovisual/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# initialize the VGG model\n",
    "vgg = VGG()\n",
    "# print(vgg)\n",
    "\n",
    "# set the evaluation mode\n",
    "vgg.eval()\n",
    "\n",
    "# get the image from the dataloader\n",
    "img, _ = next(iter(dataloader))\n",
    "\n",
    "# get the most likely prediction of the model\n",
    "# pred = vgg(img).argmax(dim=1)\n",
    "pred = vgg(img)\n",
    "# print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "077fbfcd-1e27-4bcf-a540-f657c088e2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x142abd940>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred[:, 386].backward()\n",
    "\n",
    "# pull the gradients out of the model\n",
    "gradients = vgg.get_activations_gradient()\n",
    "\n",
    "# pool the gradients across the channels\n",
    "pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "# get the activations of the last convolutional layer\n",
    "activations = vgg.get_activations(img).detach()\n",
    "\n",
    "# # weight the channels by corresponding gradients\n",
    "for i in range(512):\n",
    "    activations[:, i, :, :] *= pooled_gradients[i]\n",
    "\n",
    "# pooled_gradients = torch.mean(gradients, dim=[0, 2, 3], keepdim=True)\n",
    "# activations = activations * pooled_gradients\n",
    "    \n",
    "# average the channels of the activations\n",
    "heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "\n",
    "# relu on top of the heatmap\n",
    "# expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "\n",
    "# normalize the heatmap\n",
    "heatmap /= torch.max(heatmap)\n",
    "# print(\"heatmap:\", heatmap)\n",
    "\n",
    "# draw the heatmap\n",
    "plt.matshow(heatmap.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6647ea9-c0d8-44e0-94ed-95aaac397f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brinkley97/Documents/development/classes/csci_535_multimodal_probabilistic_learning/datasets/grad_cam_sample/elephant/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elephant_folder = PATH_TO_IMAGES + 'elephant/'\n",
    "elephant_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab3dae90-fd22-4ade-89fa-44897e384d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store', 'Elephant.png', 'output.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGES_IN_GRAD_CAMP_PATH = os.listdir(elephant_folder)\n",
    "IMAGES_IN_GRAD_CAMP_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1642744e-7176-49c0-963d-d3ef10ed8132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brinkley97/Documents/development/classes/csci_535_multimodal_probabilistic_learning/datasets/grad_cam_sample/elephant/Elephant.png'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specific_image_path = elephant_folder + IMAGES_IN_GRAD_CAMP_PATH[1]\n",
    "specific_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e485f99-7243-40e4-a86d-53275cc7b858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 419, 3)\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/opencv/opencv/issues/18120\n",
    "\n",
    "import cv2\n",
    "img = cv2.imread(specific_image_path)\n",
    "print(np.shape(img))\n",
    "print(type(heatmap))\n",
    "\n",
    "img_heatmap =np.array(np.rot90(heatmap, -4))\n",
    "reshape_heatmap = cv2.resize(img_heatmap, (419, 280))\n",
    "\n",
    "heatmap = np.uint8(255 * reshape_heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "superimposed_img = heatmap * 0.4 + img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3058bdc2-f965-4f0a-90b6-fc1b5f6f234d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_image = elephant_folder + 'output.jpg'\n",
    "cv2.imwrite(save_image, superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56aaa2f0-67e1-404b-9da7-3fb3a5a97460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shark_folder = PATH_TO_IMAGES + 'shark/'\n",
    "# shark_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32b4d20f-fc7a-4ac0-a523-cbd3c09289b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGES_IN_GRAD_CAMP_PATH_s = os.listdir(shark_folder)\n",
    "# IMAGES_IN_GRAD_CAMP_PATH_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aab67283-94aa-477d-a36e-0ae4e4492294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific_image_path_s = elephant_folder + IMAGES_IN_GRAD_CAMP_PATH_s[0]\n",
    "# specific_image_path_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0de18dfc-b689-4200-9e53-fc193e08aa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://github.com/opencv/opencv/issues/18120\n",
    "\n",
    "# import cv2\n",
    "# img = cv2.imread(specific_image_path_s)\n",
    "# print(np.shape(img))\n",
    "# print(type(heatmap))\n",
    "\n",
    "# img_heatmap =np.array(np.rot90(heatmap, -4))\n",
    "# reshape_heatmap = cv2.resize(img_heatmap, (419, 280))\n",
    "\n",
    "# heatmap = np.uint8(255 * reshape_heatmap)\n",
    "# heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "# superimposed_img = heatmap * 0.4 + img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3c9fd81-a7f2-4316-a2b5-432e9afdebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_image = elephant_folder + 'output.jpg'\n",
    "# cv2.imwrite(save_image, superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e59440-0276-4a9f-9146-1c0dd7af94ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4566d6-aefe-40c8-879d-f43b793f4bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
