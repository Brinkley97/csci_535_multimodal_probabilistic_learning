{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73285297-aaac-4a84-9674-1e34fd5954c6",
   "metadata": {},
   "source": [
    "# Extracting Features with ViT\n",
    "- https://huggingface.co/docs/transformers/model_doc/vit#vision-transformer-vit\n",
    "- https://arxiv.org/abs/2010.11929"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dec1477-5216-45f8-8bd2-a178186168bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 20:17:18.277200: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from transformers import ViTImageProcessor, ViTFeatureExtractor, ViTModel\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dba20bd1-54fe-4b63-af56-df2ee86d7a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = '/Users/brinkley97/Documents/development/'\n",
    "CLASS_PATH = 'classes/csci_535_multimodal_probabilistic_learning/'\n",
    "DATASET_PATH = 'datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4fdf4ea-1350-468c-b1a4-1bcb9379d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7b298a-0187-4d7c-860c-b61152c6583b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0f283bc-790a-4554-94f9-ce6722caff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(frames_in_crema_d):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    faces_in_specific_folder_path -- py str (of all faces in a specific folder)\n",
    "    faces_file_names -- py list (of all the file names in a specific folder)\n",
    "    \n",
    "    Return:\n",
    "    extracted_features -- py\n",
    "    \"\"\"\n",
    "    \n",
    "    extracted_features_per_video = torch.empty((0, 197, 768))\n",
    "    for path_to_specific_face in frames_in_crema_d:\n",
    "        \n",
    "        specific_frame = Image.open(path_to_specific_face)\n",
    "        # print(np.shape(specific_frame))\n",
    "\n",
    "        '''\n",
    "        Start ViT\n",
    "        '''\n",
    "\n",
    "        inputs = processor(images=specific_frame, return_tensors=\"pt\")\n",
    "        # print(inputs)\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # last_hidden_states == representation (1 and 2 with GradCam)\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        extracted_features_per_video = torch.vstack((extracted_features_per_video, last_hidden_states))\n",
    "        \n",
    "        \n",
    "    return extracted_features_per_video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220f9b18-5f69-4863-a454-274d2015bcb4",
   "metadata": {},
   "source": [
    "# CREMA-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d9d591d-229e-48ef-a2a0-28532aa24a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brinkley97/Documents/development/classes/csci_535_multimodal_probabilistic_learning/datasets/git_lfs/CREMA-D/sample_VideoFlash2/all_faces/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREMA_D_PATH = BASE + CLASS_PATH + DATASET_PATH + 'git_lfs/CREMA-D/sample_VideoFlash2/all_faces/'\n",
    "# CREMA_D_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72be197e-0a2a-4f62-a4bd-084857233adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '1001_DFA_HAP_XX_frames_to_cropped_face',\n",
       " '1001_DFA_NEU_XX_frames_to_cropped_face',\n",
       " '1001_DFA_SAD_XX_frames_to_cropped_face',\n",
       " '1001_DFA_DIS_XX_frames_to_cropped_face',\n",
       " '1001_DFA_ANG_XX_frames_to_cropped_face',\n",
       " '1001_DFA_FEA_XX_frames_to_cropped_face']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specific_emotion_folder = os.listdir(CREMA_D_PATH)\n",
    "# specific_emotion_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "523eae3e-f36b-4513-8858-9a0c2a26258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific_emotion_path = CREMA_D_PATH + specific_emotion_folder[2]\n",
    "# specific_emotion_with_frames = os.listdir(specific_emotion_path)\n",
    "# # specific_emotion_with_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1ed6462-f0cf-46d8-a8d0-244c4b9fa6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brinkley97/Documents/development/classes/csci_535_multimodal_probabilistic_learning/datasets/git_lfs/CREMA-D/sample_VideoFlash2/all_faces/1001_DFA_NEU_XX_frames_to_cropped_face/frame50.jpg'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path_for_specific_emotion_with_frames = specific_emotion_path + \"/\" + specific_emotion_with_frames[7]\n",
    "# path_for_specific_emotion_with_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a634d086-50df-4eb0-af96-47baacba3322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_features(faces_in_specific_folder_path, faces_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7827a12-b375-44be-8f70-595f355e1dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_of_fe_crema_d, fe_crema_d = get_video_path_for_feature_extraction(CREMA_D_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bdea021-aaf4-4ba7-9ecf-cc018693ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_path_for_feature_extraction(path_to_faces):\n",
    "# def get_video_path_for_feature_extraction(path_to_faces, sub_set_path):\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters:\n",
    "    path_to_faces -- str (of a single path to all saved cropped faces)\n",
    "    sub_set_path -- str (of specific sub set of the entire dataset to use)\n",
    "    \n",
    "    Function calls: \n",
    "    extract_features\n",
    "    \n",
    "    Return\n",
    "    folder, features -- tuple (of the folder the extracted features are from and the extracted features)\n",
    "    \"\"\"\n",
    "    list_folders_with_faces_name = []\n",
    "    store_features_from_faces = []\n",
    "    \n",
    "    count_number_files_in_dir = 0 \n",
    "    face_folder_files = os.listdir(path_to_faces)\n",
    "    \n",
    "    build_file_path = []\n",
    "    \n",
    "    # for face_folder_file_idx in range(len(sub_set_path)):\n",
    "        # specific_face_folder = sub_set_path[face_folder_file_idx]\n",
    "        # print(specific_face_folder)\n",
    "        \n",
    "    for face_folder_file_idx in range(len(face_folder_files)):\n",
    "        specific_face_folder = face_folder_files[face_folder_file_idx]\n",
    "        path_to_faces_in_specific_folder = path_to_faces + specific_face_folder + \"/\"\n",
    "        \n",
    "        folder_exists = os.path.isdir(path_to_faces_in_specific_folder)\n",
    "        \n",
    "        if folder_exists == True:\n",
    "            list_folders_with_faces_name.append(specific_face_folder)\n",
    "            all_faces_in_specific_folder = os.listdir(path_to_faces_in_specific_folder)\n",
    "            # print(specific_face_folder, all_faces_in_specific_folder)\n",
    "            \n",
    "            for faces_file_names_idx in range(len(all_faces_in_specific_folder)):\n",
    "                path_to_specific_face = path_to_faces_in_specific_folder + all_faces_in_specific_folder[faces_file_names_idx]\n",
    "                # print(path_to_specific_face)\n",
    "                build_file_path.append(path_to_specific_face)\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return build_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e20a931-6067-4ba9-afdb-026af7ed99cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brinkley97/Documents/development/classes/csci_535_multimodal_probabilistic_learning/datasets/git_lfs/CREMA-D/sample_VideoFlash2/all_faces/'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CREMA_D_PATH = BASE + CLASS_PATH + DATASET_PATH + 'git_lfs/CREMA-D/sample_VideoFlash2/all_faces/'\n",
    "CREMA_D_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75f3aee9-d6e7-4391-b1ee-171581ed819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_crema_d = get_video_path_for_feature_extraction(CREMA_D_PATH)\n",
    "# path_crema_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b1a36566-c4d6-4b89-832c-3fc5354c2d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CREMA-D Paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>/Users/brinkley97/Documents/development/classe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>379 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         CREMA-D Paths\n",
       "0    /Users/brinkley97/Documents/development/classe...\n",
       "1    /Users/brinkley97/Documents/development/classe...\n",
       "2    /Users/brinkley97/Documents/development/classe...\n",
       "3    /Users/brinkley97/Documents/development/classe...\n",
       "4    /Users/brinkley97/Documents/development/classe...\n",
       "..                                                 ...\n",
       "374  /Users/brinkley97/Documents/development/classe...\n",
       "375  /Users/brinkley97/Documents/development/classe...\n",
       "376  /Users/brinkley97/Documents/development/classe...\n",
       "377  /Users/brinkley97/Documents/development/classe...\n",
       "378  /Users/brinkley97/Documents/development/classe...\n",
       "\n",
       "[379 rows x 1 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crema_d_paths_to_image_df = pd.DataFrame(path_crema_d, columns=['CREMA-D Paths'])\n",
    "crema_d_paths_to_image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a70cf065-35c6-4394-b266-fe6f329859ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_in_crema_d = list(crema_d_paths_to_image_df['CREMA-D Paths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59d1f4a4-886b-42e4-954f-69c8c6b60e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames_in_crema_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0615624e-096b-49f5-ac67-9a052b785dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1296,  0.1780, -0.1627,  ..., -0.4221,  0.1744, -0.0066],\n",
       "         [-0.0081,  0.0847, -0.3951,  ..., -0.3195,  0.1200, -0.0123],\n",
       "         [-0.0699,  0.1132, -0.4551,  ..., -0.3730,  0.2579,  0.0280],\n",
       "         ...,\n",
       "         [-0.0357,  0.0704, -0.1042,  ..., -0.1797,  0.3018,  0.0598],\n",
       "         [-0.0190,  0.1394, -0.1630,  ..., -0.2395,  0.2587,  0.1013],\n",
       "         [-0.1109,  0.1001, -0.1008,  ..., -0.3130,  0.2538,  0.0512]],\n",
       "\n",
       "        [[ 0.1527,  0.1561, -0.1705,  ..., -0.3990,  0.1612, -0.0234],\n",
       "         [ 0.1020,  0.0921, -0.3429,  ..., -0.2634,  0.1970,  0.0429],\n",
       "         [-0.0990, -0.0488, -0.3809,  ..., -0.3617,  0.1873, -0.0080],\n",
       "         ...,\n",
       "         [-0.0459,  0.0547, -0.2063,  ..., -0.1403,  0.2510, -0.0671],\n",
       "         [ 0.0177,  0.1767, -0.2055,  ..., -0.1880,  0.2718,  0.0913],\n",
       "         [-0.0985,  0.0987, -0.1426,  ..., -0.2908,  0.2797, -0.0893]],\n",
       "\n",
       "        [[ 0.1380,  0.1623, -0.1639,  ..., -0.4085,  0.1629, -0.0145],\n",
       "         [ 0.0948,  0.1092, -0.3303,  ..., -0.2747,  0.2002,  0.0418],\n",
       "         [-0.1057, -0.0309, -0.3880,  ..., -0.3659,  0.1795, -0.0022],\n",
       "         ...,\n",
       "         [-0.1406,  0.0823, -0.1762,  ..., -0.1349,  0.2557, -0.0780],\n",
       "         [-0.0024,  0.1812, -0.1978,  ..., -0.2062,  0.2696,  0.1047],\n",
       "         [-0.1221,  0.1202, -0.1441,  ..., -0.2716,  0.2682, -0.0952]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.1504,  0.2080, -0.1465,  ..., -0.3966,  0.1943, -0.0164],\n",
       "         [-0.0276,  0.0245, -0.3527,  ..., -0.4144,  0.2003,  0.1060],\n",
       "         [-0.0470,  0.0465, -0.3745,  ..., -0.4479,  0.2567,  0.0529],\n",
       "         ...,\n",
       "         [ 0.0316,  0.1203, -0.1221,  ..., -0.2971,  0.3016,  0.0389],\n",
       "         [ 0.0043,  0.1983, -0.1005,  ..., -0.3309,  0.2842,  0.0569],\n",
       "         [-0.0652,  0.0859, -0.0435,  ..., -0.3799,  0.2761,  0.0009]],\n",
       "\n",
       "        [[ 0.1468,  0.1968, -0.1337,  ..., -0.4100,  0.2018,  0.0123],\n",
       "         [ 0.0895,  0.2883, -0.2760,  ..., -0.2736,  0.2533, -0.0172],\n",
       "         [-0.0566,  0.0778, -0.3082,  ..., -0.4204,  0.2167,  0.0614],\n",
       "         ...,\n",
       "         [-0.0834,  0.0889, -0.1632,  ..., -0.2623,  0.3064,  0.0109],\n",
       "         [-0.0566,  0.1519, -0.0940,  ..., -0.3226,  0.2843,  0.1237],\n",
       "         [-0.0620,  0.1679, -0.1586,  ..., -0.4631,  0.2782, -0.0519]],\n",
       "\n",
       "        [[ 0.1561,  0.2087, -0.1353,  ..., -0.4134,  0.1925,  0.0124],\n",
       "         [ 0.0632,  0.1740, -0.2821,  ..., -0.3971,  0.2340,  0.1208],\n",
       "         [-0.0332,  0.1024, -0.3385,  ..., -0.3711,  0.2276,  0.0874],\n",
       "         ...,\n",
       "         [-0.0300,  0.0842, -0.1575,  ..., -0.2981,  0.3387,  0.0618],\n",
       "         [ 0.0108,  0.1692, -0.1102,  ..., -0.3360,  0.2946,  0.1047],\n",
       "         [-0.0393,  0.1307, -0.1204,  ..., -0.4821,  0.2691, -0.0016]]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features(frames_in_crema_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b14b9-d07c-4af6-925d-158f776d45f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0ed90884-d9d3-4ad9-85c6-b5e9c8761f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "face_folder_files = os.listdir(CREMA_D_PATH)\n",
    "# print(face_folder_files)\n",
    "\n",
    "number_files_in_folder = len(next(os.walk(CREMA_D_PATH))[1])\n",
    "print(number_files_in_folder)\n",
    "\n",
    "sub_set_1 = face_folder_files[0:4]\n",
    "# print(len(sub_set_1), sub_set_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbca00d-63cd-43fc-b822-a4995e82efad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_of_fe_crema_d_1, fe_crema_d_1 = get_video_path_for_feature_extraction(CREMA_D_PATH, sub_set_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425127ce-9a19-4663-8f9b-b1b9e3bffce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe_crema_d_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312a6a6e-8d7a-4402-928c-b1185ae27f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_set_2 = face_folder_files[4:number_files_in_folder]\n",
    "# print(len(sub_set_2), sub_set_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a53bb74-3fdf-4dab-a18d-3a9efb851ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_of_fe_crema_d_2, fe_crema_d_2 = get_video_path_for_feature_extraction(CREMA_D_PATH, sub_set_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30c6b97-221e-416b-8c39-ec94ba1332aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_crema_d_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b8b30-16f2-4ff8-a298-43b97f10d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the folders of cropped faces to extract features from; #frames in single folder should match #features extracted\n",
    "# size of extracted features (all should be 196, 768) \n",
    "# fe_crema_d[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff39356f-8149-43c3-8334-1b10594422a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_storage_for_file_and_extracted_features(folder_names, features_extracted):\n",
    "    '''\n",
    "    Parameters:\n",
    "    folder_names -- py list (of file names, so 1 file per face)\n",
    "    features_extracted -- py list (features from corresponding file)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    file_name_with_features_extracted_dict = {}\n",
    "\n",
    "    for folder_name_idx in range(len(folder_names)):\n",
    "        speficic_folder = folder_names[folder_name_idx]\n",
    "        file_name_with_features_extracted_dict[speficic_folder] = features_extracted[folder_name_idx]\n",
    "\n",
    "    return file_name_with_features_extracted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099ac7e8-6d4a-4ed3-adf0-90ab1ce6f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_with_fe_crema_d = create_storage_for_file_and_extracted_features(folder_of_fe_crema_d, fe_crema_d)\n",
    "# file_with_fe_crema_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a720f40-4d70-4b6b-a0ee-bd4924b37a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a109ab-eb29-42bb-9b50-41db6f2fbf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dictionary(dictionary_to_save, save_crema_d_dict_path):\n",
    "    '''\n",
    "    Parameters:\n",
    "    dictionary_to_save -- py dic (of folder_names with corresponding features_extracted)\n",
    "    \n",
    "    '''\n",
    "    save_location = save_crema_d_dict_path + 'crema_d_extracted_features.csv'\n",
    "    # print(save_location)\n",
    "    \n",
    "    write_to_csv = csv.writer(open(save_location, \"w\"))\n",
    "\n",
    "    # loop over dictionary keys and values\n",
    "    for key, val in dictionary_to_save.items():\n",
    "\n",
    "        # write every key and value to file\n",
    "        write_to_csv.writerow([key, val])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7cdcd6-5361-4bbe-84f5-3b733bdf6a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_crema_d_dict_path = BASE + CLASS_PATH + DATASET_PATH + 'git_lfs/CREMA-D/sample_VideoFlash/' \n",
    "# save_crema_d_dict_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be55d9d8-b65b-4486-8f73-be2445a82f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dictionary(file_with_fe_crema_d, save_crema_d_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6444c750-5603-4f8f-9999-52c60b05d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISREGAURD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb116fb-3847-44c2-af02-6072334af3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_images_per_emotion(faces_in_specific_folder_path, faces_file_names):\n",
    "    '''\n",
    "    Parameters:\n",
    "    faces_in_specific_folder_path -- \n",
    "    faces_file_names -- \n",
    "    \n",
    "    Return:\n",
    "    '''\n",
    "    \n",
    "    array_of_images = []\n",
    "    for faces_file_names_idx in range(len(faces_file_names)):\n",
    "        path_to_specific_face = faces_in_specific_folder_path + faces_file_names[faces_file_names_idx]\n",
    "        \n",
    "        specific_frame = Image.open(path_to_specific_face)\n",
    "        frame_as_array = np.asarray(specific_frame)\n",
    "        # print(np.shape(frame_as_array))\n",
    "        \n",
    "        pooled_frames = np.mean(frame_as_array, axis=1)\n",
    "        # print(np.shape(pooled_frames))\n",
    "        \n",
    "        array_to_image = Image.fromarray(pooled_frames, 'RGB')\n",
    "        # print(type(array_to_image))\n",
    "        array_of_images.append(array_to_image)\n",
    "        \n",
    "    return array_of_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a76a63-b453-4e7b-b523-465526c18a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
