{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a04c941d-2580-4fd0-98e9-5e3ecb047c31",
   "metadata": {},
   "source": [
    "# Classification of Crema-D ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e6c0f33-31f9-4e3d-9d87-a8bb7a80ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import ipympl as mpl # to show (image) plots\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773a6519-8faa-4ef7-9dff-ce07eb55dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = '/Users/brinkley97/Documents/development/'\n",
    "CLASS_PATH = 'classes/csci_535_multimodal_probabilistic_learning/'\n",
    "DATASET_PATH = 'datasets/project/'\n",
    "CREMA_D_FEATURES = 'crema_d/extracted_features_crema_d/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c8087a8-186d-4a38-8ab5-81f5238a3b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_ang_extracted_features = BASE + CLASS_PATH + DATASET_PATH + CREMA_D_FEATURES + 'ang/'\n",
    "path_to_dis_extracted_features = BASE + CLASS_PATH + DATASET_PATH + CREMA_D_FEATURES + 'dis/'\n",
    "path_to_fea_extracted_features = BASE + CLASS_PATH + DATASET_PATH + CREMA_D_FEATURES + 'fea/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "814e8740-0f31-44e5-9bd4-d40d63600293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_torch_to_numpy(convert_features):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    converted = []\n",
    "    \n",
    "    for convert_features_idx in range(len(convert_features)):\n",
    "        specific_tensor = convert_features[convert_features_idx]\n",
    "        # print(specific_tensor)\n",
    "        convert = specific_tensor.detach().numpy()\n",
    "        converted.append(convert)\n",
    "    \n",
    "    return converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e4b65f3-9b10-4638-a139-c888d2354eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_extracted_features(path_to_features):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    numpy_features = []\n",
    "   \n",
    "    \n",
    "    specific_features = os.listdir(path_to_features)\n",
    "    \n",
    "    for specific_features_idx in range(len(specific_features)):\n",
    "        specific_feature = specific_features[specific_features_idx]\n",
    "        print(specific_features_idx, specific_feature)\n",
    "        \n",
    "        path_to_stored_feature = path_to_features + specific_feature\n",
    "        # print(specific_features_idx, path_to_stored_feature)\n",
    "        \n",
    "        load_features = torch.load(path_to_stored_feature)\n",
    "        # print(len(load_features))\n",
    "        \n",
    "        converted_features = convert_torch_to_numpy(load_features)\n",
    "        # numpy_features.append(converted_features)\n",
    "        \n",
    "        resampled_features = np.mean(converted_features, axis=1)\n",
    "        numpy_features.append(resampled_features)\n",
    "        \n",
    "        \n",
    "    return numpy_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5918b86e-1f69-4c44-87e4-7999e14f288b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ang_7000_extracted_features_crema_d.pt\n",
      "1 ang_3000_extracted_features_crema_d.pt\n",
      "2 ang_8000_extracted_features_crema_d.pt\n",
      "3 ang_10000_extracted_features_crema_d.pt\n",
      "4 ang_4000_extracted_features_crema_d.pt\n",
      "5 ang_2000_extracted_features_crema_d.pt\n",
      "6 ang_6000_extracted_features_crema_d.pt\n",
      "7 ang_1000_extracted_features_crema_d.pt\n",
      "8 ang_5000_extracted_features_crema_d.pt\n",
      "9 ang_11000_extracted_features_crema_d.pt\n",
      "10 ang_9000_extracted_features_crema_d.pt\n"
     ]
    }
   ],
   "source": [
    "ang_loaded_features = load_extracted_features(path_to_ang_extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6221e100-9902-4996-b49b-49a4083c414e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dis_2000_extracted_features_crema_d.pt\n",
      "1 dis_6000_extracted_features_crema_d.pt\n",
      "2 dis_1000_extracted_features_crema_d.pt\n",
      "3 dis_5000_extracted_features_crema_d.pt\n",
      "4 dis_7000_extracted_features_crema_d.pt\n",
      "5 dis_3000_extracted_features_crema_d.pt\n",
      "6 dis_4000_extracted_features_crema_d.pt\n",
      "7 dis_8000_extracted_features_crema_d.pt\n"
     ]
    }
   ],
   "source": [
    "dis_loaded_features = load_extracted_features(path_to_dis_extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46401888-7186-46b2-9163-814980734d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fea_1000_extracted_features_crema_d.pt\n",
      "1 fea_5000_extracted_features_crema_d.pt\n",
      "2 fea_2000_extracted_features_crema_d.pt\n",
      "3 fea_4000_extracted_features_crema_d.pt\n",
      "4 fea_3000_extracted_features_crema_d.pt\n"
     ]
    }
   ],
   "source": [
    "fea_loaded_features = load_extracted_features(path_to_fea_extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a9596d3-d25b-4a15-ba29-ff700bf8e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_feature_dimensions(features):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    resampled_features = np.mean(features, axis=0)\n",
    "    \n",
    "    nsamples, nx, ny = resampled_features.shape\n",
    "    reshaped_features = resampled_features.reshape((nsamples, nx*ny))\n",
    "    \n",
    "    return reshaped_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acbbf3cf-0a2d-4b7c-9ed4-016e7343986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ang_reshaped_features = reshape_feature_dimensions(ang_loaded_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "341c3f39-8fcd-49a1-9c0a-7d6739fa9193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 151296)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ang_reshaped_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffa3c414-35cb-4836-92f8-2c642141eebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ang_N = ang_reshaped_features\n",
    "len(ang_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8a17630-6b0c-49e0-9d93-546c5492b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_reshaped_features = reshape_feature_dimensions(dis_loaded_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f5e5585-fcac-44e3-936c-d83e24043eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 151296)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_reshaped_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d368f010-ccd7-478a-9b29-84f737dfb8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_N = dis_reshaped_features\n",
    "len(dis_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cc01b68-b930-47a7-a06b-94aa434b153c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dis_reshaped_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e51bb964-0c1f-4e5e-ae0d-5afc22b5a1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_reshaped_features = reshape_feature_dimensions(fea_loaded_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aec31d25-5c48-43eb-8817-b763f71c4aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_true_labels(reshaped_features, emotion_label):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    true_labels = []\n",
    "    N = len(dis_reshaped_features)\n",
    "\n",
    "    for idx in range(0, N):\n",
    "        if emotion_label == \"A\":\n",
    "            true_labels.append(\"A\")\n",
    "        if emotion_label == \"D\":\n",
    "            true_labels.append(\"D\")\n",
    "        if emotion_label == \"F\":\n",
    "            true_labels.append(\"F\")\n",
    "            \n",
    "    return true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1c2ebd5-a189-4679-8bc8-3cecd5da8a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ang_label = \"A\"\n",
    "ang_labels = create_true_labels(ang_reshaped_features, ang_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49c897a4-57fd-4909-99ef-97036540d54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ang_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c94da272-aa9d-4dbb-9e34-71ab165fbb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_label = \"D\"\n",
    "dis_labels = create_true_labels(dis_reshaped_features, dis_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb8a8513-7475-46cb-81f5-acce62c4344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dis_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "398f0a21-7a61-44e3-b986-b2c1caf88b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_label = \"F\"\n",
    "fea_labels = create_true_labels(fea_reshaped_features, fea_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "983605af-339c-4d7d-ae01-0ca00f067ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_labels = ang_labels + dis_labels + fea_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6035cb31-cc38-494a-8fc7-6852b6492d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 151296)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_features = np.concatenate((ang_reshaped_features, dis_reshaped_features, fea_reshaped_features), axis=0)\n",
    "np.shape(visual_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7633f3fa-3be6-4931-894e-5b9471b99b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(specific_features, specific_features_true_labels):\n",
    "    \"\"\"Split data into TRAIN, TEST, and VALIDATION sets\n",
    "    \n",
    "    Parameters:\n",
    "    specific_features -- list (of the reduced features)\n",
    "    specific_features_true_labels -- list (of the emotion labels that belong to that specifuc feature)\n",
    "    test_size -- float (to pass into sklearn train_test_split())\n",
    "    \n",
    "    Return:\n",
    "    X_train, X_test, X_val, y_train, y_test, y_val -- list (for that specific subset of the features)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(specific_features, specific_features_true_labels, test_size=0.2, random_state=42)\n",
    "    total_X = len(X_train) + len(X_test)\n",
    "    total_Y = len(y_train) + len(y_test)\n",
    "    \n",
    "    print(\"[INFO] X, y TRAIN sets\")\n",
    "    print(np.shape(X_train), np.shape(y_train))\n",
    "    \n",
    "    print(\"\\n[INFO] X, y TEST sets\")\n",
    "    print(np.shape(X_test), np.shape(y_test))\n",
    "    # print(\"[INFO] TOTAL TRAIN, TEST sets\")\n",
    "    # print(total_X, total_Y)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    total_X = len(X_train) + len(X_val)\n",
    "    total_Y = len(y_train) + len(y_val)\n",
    "    \n",
    "    print(\"\\n[INFO] X, y TRAIN sets\")\n",
    "    print(np.shape(X_train), np.shape(y_train))\n",
    "    \n",
    "    print(\"\\n[INFO] X, y VALIDATION sets\")\n",
    "    print(np.shape(X_val), np.shape(y_val))\n",
    "\n",
    "    \n",
    "    # return X_train, X_test, y_train, y_test\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8abc7b30-e855-4ef3-9a76-9a0b621135ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] X, y TRAIN sets\n",
      "(2400, 151296) (2400,)\n",
      "\n",
      "[INFO] X, y TEST sets\n",
      "(600, 151296) (600,)\n",
      "\n",
      "[INFO] X, y TRAIN sets\n",
      "(1920, 151296) (1920,)\n",
      "\n",
      "[INFO] X, y VALIDATION sets\n",
      "(480, 151296) (480,)\n"
     ]
    }
   ],
   "source": [
    "# X_train_visual, X_test_visual, y_train_visual, y_test_visual = split_data(visual_features, emotion_labels)\n",
    "X_train_visual, X_test_visual, X_val_visual, y_train_visual, y_test_visual, y_val_visual = split_data(visual_features, emotion_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dda6fa7-9b57-4b4c-942a-162a11573ab2",
   "metadata": {},
   "source": [
    "# Perform a Unimodal 4-Class Emotion Classification\n",
    "- Need to include validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f7bcc5-28ee-40e6-aa1a-40a2a7a1f7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training our linear support vector classification estimator\n",
      "[INFO] fitting on TRAIN...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training our linear support vector classification estimator\")\n",
    "# initialize the LinearSVC() estimator \n",
    "visual_classification_estimator = svm.LinearSVC()\n",
    "\n",
    "print(\"[INFO] fitting on TRAIN...\")\n",
    "# train the model without hyperparameter tuning\n",
    "train_without_hp_visual = visual_classification_estimator.fit(X_train_visual, y_train_visual)\n",
    "# print(train_without_hp)\n",
    "\n",
    "print(\"[INFO] classification on TEST...\")\n",
    "# make a prediction (returns a list of 0 - 4 values)\n",
    "y_pred_without_hp_visual = train_without_hp_visual.predict(X_test_visual)\n",
    "\n",
    "visual_classification_report_without_hp = classification_report(y_test_visual, y_pred_without_hp_visual)\n",
    "print(visual_classification_report_without_hp)\n",
    "\n",
    "# show true labels and predictions\n",
    "visual_cm = confusion_matrix(y_test_visual, y_pred_without_hp_visual)\n",
    "sns.heatmap(visual_cm, annot=True, cmap='viridis')\n",
    "plt.show()\n",
    "\n",
    "print(\"[INFO] evaluating on TEST...\")\n",
    "test_without_hp_visual = train_without_hp_visual.score(X_test_visual, y_test_visual)\n",
    "print(test_without_hp_visual)\n",
    "\n",
    "visual_f1_micro_without_hp = f1_score(y_test_visual, y_pred_without_hp_visual, average='micro')\n",
    "print(visual_f1_micro_without_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa39a63c-268f-44d6-8e93-66c5f040b429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
