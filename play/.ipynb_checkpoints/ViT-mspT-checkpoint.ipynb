{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73285297-aaac-4a84-9674-1e34fd5954c6",
   "metadata": {},
   "source": [
    "# Extracting Features with ViT\n",
    "- https://huggingface.co/docs/transformers/model_doc/vit#vision-transformer-vit\n",
    "- https://arxiv.org/abs/2010.11929"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dec1477-5216-45f8-8bd2-a178186168bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "# import csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "# from PIL import Image\n",
    "# from transformers import ViTImageProcessor, ViTFeatureExtractor, ViTModel\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dba20bd1-54fe-4b63-af56-df2ee86d7a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = '/Users/brinkley97/Documents/development/'\n",
    "CLASS_PATH = 'classes/csci_535_multimodal_probabilistic_learning/'\n",
    "DATASET_PATH = 'datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fdf4ea-1350-468c-b1a4-1bcb9379d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61987b25-6171-43d0-b448-b097b3447425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    original_data = pd.read_csv(file)\n",
    "    # original_data = pd.DataFrame(file)\n",
    "    copy_of_data = original_data.copy()\n",
    "    return copy_of_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58cb5d2-21d4-4523-a66a-27255a7b5234",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = BASE + CLASS_PATH + DATASET_PATH + 'cremaD_mspR_mspT.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a6401e-3beb-497b-8666-8f209a9c9130",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_paths_copy = load_data(file_paths)\n",
    "# dataset_paths_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403ea4dd-01a5-447a-8044-e2d3df4a3d22",
   "metadata": {},
   "source": [
    "# MSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a76a63-b453-4e7b-b523-465526c18a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSP_DATASET_PATH = 'msp/videos/r_and_t_frames/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02fd03d-4851-4ff3-aafc-adae7976ec18",
   "metadata": {},
   "source": [
    "## T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfaa9be-33bf-48e0-82ca-066ec2d85948",
   "metadata": {},
   "outputs": [],
   "source": [
    "msp_t_paths = dataset_paths_copy['MSP T Paths']\n",
    "type(msp_t_paths), msp_t_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0953c80-bde0-4d3f-b332-0fae6f7f2242",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_set_msp_t_paths = msp_t_paths.loc[0:300]\n",
    "sub_set_msp_t_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011d6580-7575-4b36-8432-2d0a5c521f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# msp_t_df = pd.DataFrame(sub_set_msp_t_paths, columns=['MSP T Paths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95ffea1-f5f0-438d-96fb-4830fdac5d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "    \n",
    "for msp_t_path_idx in range(len(sub_set_msp_t_paths)):\n",
    "    # print(msp_t_path_idx)\n",
    "    msp_t_path = msp_t_paths[msp_t_path_idx]\n",
    "    \n",
    "    specific_frame = Image.open(msp_t_path)\n",
    "    # print(np.shape(specific_frame))\n",
    "\n",
    "    inputs = processor(images=specific_frame, return_tensors=\"pt\")\n",
    "    x.append(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0b9ff0-eed1-480a-8192-f8208e5f325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8adaf60-0426-4046-b7f2-c95c423ee199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5cda3d-9504-40c1-84e8-33212bd4f68a",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abead98-e187-4a0c-ad34-dc7cd7c02531",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_set_msp_t = BASE + CLASS_PATH + DATASET_PATH + 'subsets_vit/' +'inputs-mspT_subset.txt'\n",
    "sub_set_msp_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf73e8c2-b5da-49de-b6df-e9821127f47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sub_set_msp_t, 'wb') as f:\n",
    "    pickle.dump(x, f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a1a3e8-451f-485d-a745-747f5b5cf32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reading_sub_set_msp_t = pd.read_pickle(sub_set_msp_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac33299-c77d-401f-ae8e-748613abb85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading_sub_set_msp_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158e9f75-b91b-43f9-9109-ae08716556a9",
   "metadata": {},
   "source": [
    "# Hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e72bfd-0ed3-497f-acb4-f457bdd9e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_last_hidden_states = []\n",
    "\n",
    "for specific_frame in range(len(reading_sub_set_msp_t)):\n",
    "    inputs = reading_sub_set_msp_t[specific_frame]\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "    # last_hidden_states == representation (1 and 2 with GradCam)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    all_last_hidden_states.append(last_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "939260f6-3512-433b-8a4b-60d91433fbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "msp_t_hidden_states = BASE + CLASS_PATH + DATASET_PATH + 'subsets_vit/' + 'hiddenStates-mspT_subset.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cdd672-6609-4237-b0a0-2c16903e5c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(msp_t_hidden_states, 'wb') as f:\n",
    "    pickle.dump(all_last_hidden_states, f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ec4bf77-4d02-49fe-9a3f-afa7633245ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "reading_msp_t_hidden_states = pd.read_pickle(msp_t_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6076928e-310c-4c76-8581-596cf9c42765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading_msp_t_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c62fbdd-8aea-4765-afed-aef04ef5be75",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_per_video = torch.empty((0, 197, 768))\n",
    "save_efs = []\n",
    "for specific_frame_hs in range(len(reading_msp_t_hidden_states)):\n",
    "    \n",
    "    hs = reading_msp_t_hidden_states[specific_frame_hs]\n",
    "    extracted_features_per_video = torch.vstack((extracted_features_per_video, hs))\n",
    "    \n",
    "    save_efs.append(extracted_features_per_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3757617b-0580-4e0e-87e3-7cb4266c946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_efs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03e02e12-9849-428e-9631-c3379ad99f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_msp_t_extracted_features = BASE + CLASS_PATH + DATASET_PATH + 'subsets_vit/' + 'extractedFeatures-mspT.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afe08239-5296-47af-a584-8eb05964fbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(save_efs, sample_msp_t_extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f8a82cf-d1cc-4c86-a0d8-1ea5662064b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_msp_t = torch.load(sample_msp_t_extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8ebb54-cedb-4a6a-9065-db8070f346ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_msp_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0074a8b-40aa-47c7-9829-ba01c42c666a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
