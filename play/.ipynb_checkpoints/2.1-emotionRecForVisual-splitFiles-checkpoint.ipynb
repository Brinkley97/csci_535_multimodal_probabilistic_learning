{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73285297-aaac-4a84-9674-1e34fd5954c6",
   "metadata": {},
   "source": [
    "# Emotion Recognition for Visual\n",
    "- Various splitting methods. None working like we need to split the folders of frames. They only split videos or nothing at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dec1477-5216-45f8-8bd2-a178186168bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import splitfolders\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 'from transtormers 1moort ViTreatureextractor\n",
    "from transformers import ViTImageProcessor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dba20bd1-54fe-4b63-af56-df2ee86d7a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brinkley97/Documents/development/classes/csci_535_multimodal_probabilistic_learning/datasets/msp/videos/r_and_t_videos/\n"
     ]
    }
   ],
   "source": [
    "# /Users/brinkley97/Documents/development/classes/csci_535_multimodal_probabilistic_learning/datasets/\n",
    "\n",
    "BASE = '/Users/brinkley97/Documents/development/'\n",
    "CLASS_PATH = 'classes/csci_535_multimodal_probabilistic_learning/'\n",
    "DATASET_PATH = 'datasets/'\n",
    "MSP_DATASET_PATH = 'msp/videos/'\n",
    "MSP_VIDEO_FILES = 'full_r_and_t_mspVideoPaths.csv'\n",
    "MSP_video_file_paths = BASE + CLASS_PATH + DATASET_PATH + MSP_DATASET_PATH + MSP_VIDEO_FILES\n",
    "\n",
    "r_and_t_video_files = BASE + CLASS_PATH + DATASET_PATH + MSP_DATASET_PATH + 'r_and_t_videos/'\n",
    "print(r_and_t_video_files)\n",
    "# r_video_files = r_and_t_video_files + 'r_frames/'\n",
    "# print(r_video_files)\n",
    "# t_video_files = r_and_t_video_files + 't_videos'\n",
    "\n",
    "# r_and_t_video_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc857f8-2bde-4e63-b8d6-de25d74f33b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    original_data = pd.read(csvfile)\n",
    "    # original_data = pd.DataFrame(file)\n",
    "    copy_of_data = original_data.copy()\n",
    "    return copy_of_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d7805e-92f1-475a-b326-4df546c80fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 classes - ander, happiness, neutral, sadness\n",
    "# dataset_paths_copy = load_data_video_file(paths)\n",
    "# dataset_paths_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fdf4ea-1350-468c-b1a4-1bcb9379d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = ViTImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f283bc-790a-4554-94f9-ce6722caff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(path_to_video_frames, video_with_frames):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    path_to_video_frames -- py str (of path to each list of frames per video)\n",
    "    video with frames -- py list (of frame file name per video)\n",
    "    Return:\n",
    "    extracted_features -- py\n",
    "    \"\"\"\n",
    "    \n",
    "    extracted_features_per_video = []\n",
    "    \n",
    "    for video_with_frame in range(len(video_with_frames)):\n",
    "        frame_path_with_frames = path_to_video_frames + video_with_frames[video_with_frame]\n",
    "        # print(frame_path_with_frames)\n",
    "        # extracted_feature_per_frame = feature_extractor(frame_path_with_frames, return_tensors='pt')\n",
    "        # extracted_features_per_video.append(extracted_feature_per_frame)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83d27b2-49b0-4304-a746-dbfd40395e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(number_files_in_dir):\n",
    "    \"\"\"Split data into TRAIN, TEST, and VALIDATION sets\n",
    "    \n",
    "    Parameters:\n",
    "    files_to_split -- list (of the reduced features)\n",
    "    r_or_t -- str (either r or t)\n",
    "    test_size -- float (to pass into sklearn train_test_split())\n",
    "    \n",
    "    Return:\n",
    "    X_train, X_test, X_val, y_train, y_test, y_val -- list (for that specific subset of the features)\n",
    "    \n",
    "    \"\"\"\n",
    "    number_files_in_dir\n",
    "    \n",
    "    \n",
    "    \n",
    "#     print(len(files_to_split), files_to_split)\n",
    "    \n",
    "#     range_true_labels = range(0, len(files_to_split))\n",
    "#     # print(range_true_labels)\n",
    "    \n",
    "#     true_labels = [] \n",
    "#     for range_true_label in range_true_labels:\n",
    "#         if r_or_t == 'r':\n",
    "#             true_labels.append('r')\n",
    "#         elif r_or_t == 't':\n",
    "#             true_labels.append('t')\n",
    "#         else:\n",
    "#             print(\"Invalid\")\n",
    "    \n",
    "    \n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(files_to_split, true_labels, test_size=0.6, random_state=42)\n",
    "#     total_X = len(X_train) + len(X_test)\n",
    "#     total_Y = len(y_train) + len(y_test)\n",
    "    \n",
    "#     print(\"[INFO] X, y TRAIN sets\")\n",
    "#     print(np.shape(X_train), np.shape(y_train))\n",
    "    \n",
    "#     print(\"\\n[INFO] X, y TEST sets\")\n",
    "#     print(np.shape(X_test), np.shape(y_test))\n",
    "#     print(X_test)\n",
    "#     # print(\"[INFO] TOTAL TRAIN, TEST sets\")\n",
    "#     # print(total_X, total_Y)\n",
    "    \n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.7, random_state=42)\n",
    "#     total_X = len(X_train) + len(X_val)\n",
    "#     total_Y = len(y_train) + len(y_val)\n",
    "    \n",
    "#     print(\"\\n[INFO] X, y TRAIN sets\")\n",
    "#     print(np.shape(X_train), np.shape(y_train))\n",
    "    \n",
    "#     print(\"\\n[INFO] X, y VALIDATION sets\")\n",
    "#     print(np.shape(X_val), np.shape(y_val))\n",
    "\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95892bb6-82e6-4b11-bf81-f1ac7ca420a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = 'r'\n",
    "# X_train, X_test, X_val, y_train, y_test, y_val = split_data(r_frames_files, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca3ac81-b47d-4c67-afbf-2f63421265a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdea021-aaf4-4ba7-9ecf-cc018693ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_path(videos, test_train_validate_folders):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    videos\n",
    "    feature_extractor -- transformers\n",
    "    Function calls: extract_features\n",
    "    Return\n",
    "    \"\"\"\n",
    "    \n",
    "    count_number_files_in_dir = 0\n",
    "    # print (videos)\n",
    "    get_videos = os.listdir(videos)\n",
    "    # print(get_videos)\n",
    "    for get_video in range(len(get_videos)):\n",
    "        print(\"GET FRAMES FOR VIDEO: \", get_video, get_videos[get_video])\n",
    "        path_to_video_frames = videos + get_videos[get_video] + \"/\"\n",
    "        # print(path_to_video_frames)\n",
    "        path_to_frames = videos\n",
    "        print(path_to_frames)\n",
    "        \n",
    "        folder_exists = os.path.isdir(path_to_video_frames)\n",
    "        # print(folder_exists)\n",
    "        if folder_exists == True:\n",
    "            \n",
    "            # print(frame path)\n",
    "            list_frames_per_video = os.listdir(path_to_video_frames)\n",
    "            # print(list_frames_per_video)\n",
    "            # print(\"VIDEO FRAMES FOR: \", count_number_files_in_dir, path_to_video_frames)\n",
    "            splitfolders.ratio(path_to_frames, output=test_train_validate_folders, seed=1337, ratio=(.6, 0.2, 0.2)) \n",
    "            # extract_features(path_to_video_frames, list_frames_per_video)\n",
    "            # print()\n",
    "            count_number_files_in_dir += 1\n",
    "        else:\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9d591d-229e-48ef-a2a0-28532aa24a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPD_DATASET_PATH = \"ipd_data/IPD_videos/\"\n",
    "IPD_VIDEOS = BASE + CLASS_PATH + DATASET_PATH + IPD_DATASET_PATH\n",
    "# print(IPD_VIDEOS)\n",
    "# get_video_path(IPD_VIDEOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af85356e-df12-4933-a2e5-a148994249cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brinkley97/Documents/development/classes/csci_535_multimodal_probabilistic_learning/datasets/msp/videos/r_and_t_videos/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 1272 files [00:16, 79.22 files/s]\n"
     ]
    }
   ],
   "source": [
    "test_train_validate_folders = BASE + CLASS_PATH + DATASET_PATH + MSP_DATASET_PATH + 'frames_r_and_t_test_train_validate/'\n",
    "print(r_and_t_video_files)\n",
    "splitfolders.ratio(r_and_t_video_files, output=test_train_validate_folders, seed=1337, ratio=(.6, 0.2, 0.2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa18390-0e1f-42b0-b455-ddc31aba8b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc06c3c-b53d-457f-afb4-229c73356f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPD_DATASET_PATH = \"ipd_data/IPD_videos/\"\n",
    "# IPD_VIDEOS = BASE + CLASS_PATH + DATASET_PATH + IPD_DATASET_PATH\n",
    "# print(IPD_VIDEOS)\n",
    "test_train_validate_folders = BASE + CLASS_PATH + DATASET_PATH + MSP_DATASET_PATH + 'r_and_t_test_train_validate/'\n",
    "# get_video_path(r_and_t_video_files, test_train_validate_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d4a70c-2da6-4b85-be6a-82829402b3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
