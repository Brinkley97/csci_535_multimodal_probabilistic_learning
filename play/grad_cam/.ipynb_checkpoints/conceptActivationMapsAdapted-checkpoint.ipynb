{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c6506bd-2bbc-476b-99fe-0b7b7493d72b",
   "metadata": {},
   "source": [
    "# Tutorial: Concept Activation Maps\n",
    "\n",
    "https://jacobgil.github.io/pytorch-gradcam-book/Pixel%20Attribution%20for%20embeddings.html#tutorial-concept-activation-maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb206f7-9f45-45ec-ba54-775cb122606e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install torchvision\n",
    "# !pip install grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fade76e4-f2c5-4948-b4ba-ac8fcc04db2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import requests\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import torch.functional as F\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from PIL import Image\n",
    "from pytorch_grad_cam import GradCAM\n",
    "# from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image\n",
    "from transformers import ResNetModel, ViTModel, AutoImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6583f806-707c-49cd-af29-780de9892307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE = '/Users/brinkley97/Documents/development/'\n",
    "CLASS_PATH = 'classes/csci_535_multimodal_probabilistic_learning/'\n",
    "DATASET_PATH = 'datasets/project/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc106fa-dbbe-40cb-a275-7df91fb560cd",
   "metadata": {},
   "source": [
    "# ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3376f48e-a148-4097-9abe-92381ad7d7e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTModel(\n",
       "  (embeddings): ViTEmbeddings(\n",
       "    (patch_embeddings): ViTPatchEmbeddings(\n",
       "      (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (encoder): ViTEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x ViTLayer(\n",
       "        (attention): ViTAttention(\n",
       "          (attention): ViTSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ViTSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ViTIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ViTOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (pooler): ViTPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# google\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "vit_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "vit_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd1169-fdd1-4717-8ad6-a8215b73eff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_from_url(image):\n",
    "    \"\"\"A function that gets a URL of an image, \n",
    "    and returns a numpy image and a preprocessed\n",
    "    torch tensor ready to pass to the model \"\"\"\n",
    "\n",
    "    img = np.array(Image.open(requests.get(url, stream=True).raw))\n",
    "    img = cv2.resize(img, (512, 512))\n",
    "    rgb_img_float = np.float32(img) / 255\n",
    "    input_tensor = preprocess_image(rgb_img_float,\n",
    "                                   mean=[0.485, 0.456, 0.406],\n",
    "                                   std=[0.229, 0.224, 0.225])\n",
    "    return img, rgb_img_float, input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c71bcf6-5fdf-4f4e-a258-eda0e68e2c5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# car_img, car_img_float, car_tensor = get_image_from_url(\"https://www.wallpapersin4k.org/wp-content/uploads/2017/04/Foreign-Cars-Wallpapers-4.jpg\")\n",
    "# cloud_img, cloud_img_float, cloud_tensor = get_image_from_url(\"https://th.bing.com/th/id/OIP.CmONj_pGCXg9Hq9-OxTD9gHaEo?pid=ImgDet&rs=1\")\n",
    "# car_concept_features = model(car_tensor)[0, :]\n",
    "# cloud_concept_features = model(cloud_tensor)[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7df28664-e452-4ada-8fcd-4e31367e6a80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'car_concept_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcar_concept_features\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'car_concept_features' is not defined"
     ]
    }
   ],
   "source": [
    "car_concept_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a34a3-2e6e-47ee-9ec8-ae945e2df303",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image.fromarray(np.hstack((cloud_img, car_img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038cba8-cfc6-489b-a1ff-b79d0d08d8ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image, image_float, input_tensor = get_image_from_url(\"https://th.bing.com/th/id/R.c65135374de94dea2e2bf8fe0a4818e7?rik=Z75HF5uFr56PAw&pid=ImgRaw&r=0\")\n",
    "Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fff527b-f75b-4090-bbe6-9dfa910a6517",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimilarityToConceptTarget:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "    \n",
    "    def __call__(self, model_output):\n",
    "        cos = torch.nn.CosineSimilarity(dim=0)\n",
    "        return cos(model_output, self.features)\n",
    "    \n",
    "target_layers = [resnet.layer4[-1]]\n",
    "car_targets = [SimilarityToConceptTarget(car_concept_features)]\n",
    "cloud_targets = [SimilarityToConceptTarget(cloud_concept_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4732e11-bfc7-48f7-b030-0c067dd1fdef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Where is the car in the image\n",
    "with GradCAM(model=model,\n",
    "             target_layers=target_layers,\n",
    "             use_cuda=False) as cam:\n",
    "    car_grayscale_cam = cam(input_tensor=input_tensor,\n",
    "                        targets=car_targets)[0, :]\n",
    "car_cam_image = show_cam_on_image(image_float, car_grayscale_cam, use_rgb=True)\n",
    "Image.fromarray(car_cam_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008224a0-a43a-4110-aae1-06c3c396b0a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Where is the cloud in the image\n",
    "with GradCAM(model=model,\n",
    "             target_layers=target_layers,\n",
    "             use_cuda=False) as cam:\n",
    "    cloud_grayscale_cam = cam(input_tensor=input_tensor,\n",
    "                        targets=cloud_targets)[0, :]\n",
    "cloud_cam_image = show_cam_on_image(image_float, cloud_grayscale_cam, use_rgb=True)\n",
    "Image.fromarray(cloud_cam_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fad653-b8cb-4060-8d30-dd5cbfbedf88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
